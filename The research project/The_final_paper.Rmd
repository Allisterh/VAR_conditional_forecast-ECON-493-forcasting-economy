---
output:
  word_document: default
  html_document: default
  latex_engine: xelatex
  pdf_document: default
fontsize: 12pt
mainfont: Times New Roman
---

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(ggplot2)
library(fpp2)
library(glmnet)
library(tidyr)
library(lmtest)
library(boot)
library(forecast)
library(readr)
library(ggfortify)
library(tseries)
library(urca)
library(readxl)
library(lubridate)
library(cansim)
library(OECD)
library(WDI)
library(fredr)
library(tsbox)
library(RColorBrewer)
library(wesanderson)
library(writexl)
library(gridExtra)
library(vars)
library("ggthemes")
```

The data set used this paper are published by the whatever it is


```{r message=FALSE, include=FALSE, paged.print=FALSE}
#1.import the data
Can_housing_sell_data.raw <- read_excel("/Users/tie/Documents/GitHub/ECON-493-forcasting-economy/The research project/News_release_chart_data_mar_2023.xlsx", sheet = "Chart A", col_types = c("date",  "numeric", "numeric", "skip", "skip"))

#transfer data to ts form
Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023, 2), frequency = 12)
```


The data is relative to the canadian housing reslate data from 2007 to 2023, by using this data, we could futhury sytudent waht is going on Canadian housing makret.

This paper is fousing on study how canadian housing market will respond to thepolicy rate change if Bank of Canadian remine the policy rate high as 4.5%. 

Author using the housing reslce data m and ther avalidalt macro data to consturion one ARIMA model and VAR model to conditional forecast if canaidna hosuing go over 45. 




```{r echo=FALSE, message=FALSE, warning=FALSE}
autoplot(Can_month_housing_sell.ts) +
   theme_fivethirtyeight() + 
   xlab("Year") +
  ylab("Housing Sell") +
  ggtitle("Canaidan housing resales from 2007 to 2023") +
   theme(axis.title = element_text())

  

#1.1.2 the seaonal plot
Can_month_housing_sell_plot_ts<- ts(Can_housing_sell_data.raw$Canada, start = c(2010, 1), end = c(2019, 1), frequency = 12)

#1.1.3 the seasonality graphy
ggsubseriesplot(Can_month_housing_sell_plot_ts) +
  ylab("number of home saled") +
   theme_fivethirtyeight() +
   xlab("month") +
  ylab("Housing Sell") +
  ggtitle("Canadian housing resales Sesaonal") +
  labs(subtitle = "housing resales are higher in the summary") + 
  theme(axis.title = element_text())


#stationary_CA_GDP.ts

#autoplot(stationary_CA_GDP.ts) +
   theme_fivethirtyeight() + 
   xlab("Year") +
  ylab("percentage") +
  ggtitle("Canadian norminal GDP growth rate (2002 = 100)") +
   theme(axis.title = element_text())




```
As shown in this graph, we can easily identify the trend of housing with the business cycle. The first drop can be explained as the dramatic impact of the 2008 financial crisis on the housing market. Another significant jump occurred around the beginning of 2020, when the first COVID-19 case was discovered in Canada, and COVID-19 became a global pandemic. Furthermore, as COVID-19 cases increased, the Canadian federal and provincial governments implemented COVID-19 restrictions to curb the spread, and the Bank of Canada lowered its policy rate to support the Canadian economy. As a result, there was a significant spike in housing sales. However, once the COVID-19 situation began to improve, and the war in Korea pushed up global energy prices, inflation in Canada reached an 8% 40-year high, resulting in a rising policy rate. As a result, the housing market began to cool down, and housing sales started to decline. 





Part One: Constructing the ARIMA Model

To better analyze the data, the author constructed four ARIMA models using different time periods. The first model used the entire data set from 2007 to 2023, while the second focused on the period from 2016 to 2023, during the COVID-19 pandemic. The third model covered the period from 2009 July, when the 2008 recession ended, to 2023, and the fourth model covered the period from 2007 to 2019 January, with the aim of avoiding the impact of COVID-19.

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
#data
#The entire data 
Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023, 1), frequency = 12)

#The data set without 2008
after_2008_forecasting_data <- window(Can_month_housing_sell.ts, start= c(2009,7), end= c(2023,1))

#the Data from 2016 to 2023
The_before_during_after_Covid_model.data<-window(Can_month_housing_sell.ts, start= c(2016,1), end= c(2023,2))

#The data from 2007 to 2019 (the entire data without Covid shock)
Can_month_housing_sell_without_covid_shock.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2019, 1), frequency = 12)

#The data from 2008 to 2019 (After recession without covid shock)
after_2008_forecasting_without_covid_shock_data <- window(Can_month_housing_sell.ts, start= c(2009,7), end= c(2019, 1))

from_2007_to_2017 <- window(Can_month_housing_sell.ts, start= c(2007,1), end= c(2017, 1))
  

#construed model
all_data_model_1 <- auto.arima(Can_month_housing_sell.ts, 
                               approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                               num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                               start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                               max.d = 5, max.p = 5, max.q = 5)

all_data_model_2 <- auto.arima(Can_month_housing_sell.ts)

after_2008_forecasting_model_1 <- auto.arima(after_2008_forecasting_data, 
                                             approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                             num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                             start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                             max.d = 5, max.p = 5, max.q = 5)

after_2008_forecasting_model_2 <- auto.arima(after_2008_forecasting_data)

The_before_during_after_Covid_model_1 <- auto.arima(The_before_during_after_Covid_model.data, d = 1,
                                                    approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                                    num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                                    start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                                    max.d = 5, max.p = 5, max.q = 5)

The_before_during_after_Covid_model_2 <- auto.arima(The_before_during_after_Covid_model.data, d=1)

entil_data_without_covid_shock_1<- auto.arima(Can_month_housing_sell_without_covid_shock.ts, 
                                              approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                              num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                              start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                              max.d = 5, max.p = 5, max.q = 5)

test_model_one_after_2008_forecasting_without_covid_shock_1 <- auto.arima(after_2008_forecasting_without_covid_shock_data,
                                                                          approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                                                          num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                                                          start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                                                          max.d = 5, max.p = 5, max.q = 5)

entil_data_without_covid_shock_2 <- auto.arima(Can_month_housing_sell_without_covid_shock.ts)

test_model_one_after_2008_forecasting_without_covid_shock_2 <- auto.arima(after_2008_forecasting_without_covid_shock_data)

from_2007_to_2017_1 <- auto.arima(from_2007_to_2017,
                                  approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                  num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                  start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                  max.d = 5, max.p = 5, max.q = 5)

from_2007_to_2017_2 <- auto.arima(from_2007_to_2017)


####################
# Create a data frame with the names and ARIMA models
models_table <- data.frame(
  ARIMA = c(as.character(all_data_model_1), as.character(all_data_model_2), as.character(after_2008_forecasting_model_1), as.character(after_2008_forecasting_model_2),
            as.character(The_before_during_after_Covid_model_1), as.character(The_before_during_after_Covid_model_2), as.character(test_model_one_after_2008_forecasting_without_covid_shock_1),
            as.character(test_model_one_after_2008_forecasting_without_covid_shock_2), as.character(entil_data_without_covid_shock_1), as.character(entil_data_without_covid_shock_2),
            as.character(from_2007_to_2017_1), as.character(from_2007_to_2017_2))
)

# Print the table
print(models_table)
```


After doing het different airma function 12 times, we got 12 different arime function while most of them are repace with self. 

```{R echo=FALSE, message=FALSE, warning=FALSE}
model_table_2 <- data.frame(
  Model = c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]", "ARIMA(0,1,0)")
)
print(model_table_2)

```


next,we will going to evaluate the different model to find out witch one is the best.
first, let compare their AIC and BIC

By fit the all different ARIMA cobmine into the data that without covid-19 impact to see which mode is working better on fit the model wihtout covid 19

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
#fit the model into the entire data.
Can_month_housing_sell_without_Covid.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2019, 1), frequency = 12)

# Fit the ARIMA(2,1,0) model
model1_Without_Covid<- Arima(Can_month_housing_sell_without_Covid.ts, order=c(2,1,0))

# Fit the ARIMA(0,1,1) model
model2_Without_Covid<- Arima(Can_month_housing_sell_without_Covid.ts, order=c(0,1,1))

# Fit the ARIMA(2,1,2)(0,0,1)[12] model with zero mean
model3_Without_Covid <- Arima(Can_month_housing_sell_without_Covid.ts, order=c(2,1,2), seasonal=list(order=c(0,0,1), period=12))

# Fit the ARIMA(0,1,0) model
model4_Without_Covid <- Arima(Can_month_housing_sell_without_Covid.ts, order=c(0,1,0))



#4.3 AIC and BIC for data without covid.
AIC_and_BIC_Matrix_for_without_covid<- matrix (ncol = 2, nrow = 4)
colnames(AIC_and_BIC_Matrix_for_without_covid) <-c("AIC","BIC")
rownames(AIC_and_BIC_Matrix_for_without_covid) <-c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]", "ARIMA(0,1,0)")
AIC_and_BIC_Matrix_for_without_covid[1,1] <- AIC(model1_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[2,1] <- AIC(model2_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[3,1] <- AIC(model3_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[4,1] <- AIC(model4_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[1,2] <- BIC(model1_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[2,2] <- BIC(model2_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[3,2] <- BIC(model3_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[4,2] <- BIC(model4_Without_Covid)
print(AIC_and_BIC_Matrix_for_without_covid)

```
As the output show, the ARIMA(2,1,2)(0,0,1)[12], it may relace to this combination is generate base on the data from 2007 to 2019, which are not suprised at all.


compare the AIC and BIC model base on the data that including the covid influence.
```{r echo=FALSE}
#fit the model into the entire data.
Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023, 1), frequency = 12)

# Fit the ARIMA(2,1,0) model
model1<- Arima(Can_month_housing_sell.ts, order=c(2,1,0))

# Fit the ARIMA(0,1,1) model
model2<- Arima(Can_month_housing_sell.ts, order=c(0,1,1))

# Fit the ARIMA(2,1,2)(0,0,1)[12] model with zero mean
model3 <- Arima(Can_month_housing_sell.ts , order=c(2,1,2), seasonal=list(order=c(0,0,1), period=12))

# Fit the ARIMA(0,1,0) model
model4<- Arima(Can_month_housing_sell.ts , order=c(0,1,0))

#AIC and BIC for the entire data
AIC_and_BIC_Matrix <- matrix (ncol = 2, nrow = 4)
colnames(AIC_and_BIC_Matrix) <-c("AIC","BIC")
rownames(AIC_and_BIC_Matrix) <-c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]", "ARIMA(0,1,0)")
AIC_and_BIC_Matrix[1,1] <- AIC(model1)
AIC_and_BIC_Matrix[2,1] <- AIC(model2)
AIC_and_BIC_Matrix[3,1] <- AIC(model3)
AIC_and_BIC_Matrix[4,1] <- AIC(model4)
AIC_and_BIC_Matrix[1,2] <- BIC(model1)
AIC_and_BIC_Matrix[2,2] <- BIC(model2)
AIC_and_BIC_Matrix[3,2] <- BIC(model3)
AIC_and_BIC_Matrix[4,2] <- BIC(model4)
print(AIC_and_BIC_Matrix)
```
Unsprised, the ARIMA(2,1,0) is best accrding to it AIC value, due to its fit by from the entire data set. 


Futher, let's do the cross validation of four model on the data that inculding the covid and without the cov

the cross valdation

Furthermore, let's perform cross-validation on four models using data that includes and excludes the COVID period. The cross-validation process involves training the models using data up to 2016 and testing them using data from 2016 to 2019. Assuming that the relationship between housing sales and other macroeconomic factors remains the same in the post-COVID period, we can focus on the market's behavior during normal times and ignore the impact of COVID. Therefore, this cross-validation test starts with the training set from 2007 to 2015 and uses the dataset from 2016 to 2018 for testing to evaluate the model's goodness.


The training set: 2007 - 2020
The test set: 2020 - 2022
```{r echo=FALSE, paged.print=FALSE}

Can_month_housing_sell_test.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023,1), frequency = 12)

#(2023 - 2018)
n.end <- 2017
n_test <- 12 * 2 #the times we need go
n_models <- 4  
h.val <- 1 

#set the martix pred
pred <- matrix(rep(NA, n_test * (n_models + 1)), nrow=n_test, ncol=(n_models + 1)) 

# the for loop
for (i in 1: n_test ) {
  tmp0 <- 2007 #the training start at 2007 
  tmp1 <- n.end + (i - 2) * (1/12) #the end of training windows 
  tmp <- window(Can_month_housing_sell_test.ts, start=tmp0, end=tmp1) 
  #the training data set from 2007 to the date to its end
  #2007 to 2016 + (observation windos)

  
#The acutally value
  pred[i, 1] <- window(Can_month_housing_sell.ts, start=tmp1 + (1/12), end=tmp1 + (1/12))
  
#moding time!
  fit1 <- Arima(tmp, order=c(2,1,0))
  fit2 <- Arima(tmp, order=c(0,1,1))
  fit3 <- Arima(tmp, order=c(2,1,2), seasonal=list(order=c(0,0,1), period=12))
  fit4 <- Arima(tmp, order=c(0,1,0))
  
#one step
  pred[i, 2] <- forecast(fit1, h= h.val)$mean[h.val]
  pred[i, 3] <- forecast(fit2, h= h.val)$mean[h.val]
  pred[i, 4] <- forecast(fit3, h= h.val)$mean[h.val]
  pred[i, 5] <- forecast(fit4, h= h.val)$mean[h.val]
}

#calculate the error

error <- (pred[, -1] - pred[, 1])
mse <- colMeans(error)
rmse <- sqrt(colMeans(error^2))
mae <- colMeans(abs(error))
mpe <- colMeans((error/ pred[, 1]) * 100)
mape <- colMeans(abs((error/ pred[, 1]) * 100))

#The outcome
The_evil_df <- data.frame(
  Model = c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]",  "ARIMA(0,1,0)"),
  ME = mse,
  RMSE = rmse,
  MAE = mae,
  MPE = mpe,
  MAPE = mape
)

print(The_evil_df)


```


The training set: 2007 - 2021
The test set: 2023 - 2022









Based on the provided error metrics, the best model appears to be ARIMA(0,1,1) as it has the lowest MAE (1977.793) and the second-lowest MAPE (5.568452). Lower error metrics indicate better model performance.
however, ARIMA(2,1,0) has the lowest AIC in both with or without covid influence.it suggests that this model might be the best balance between model complexity and goodness of fit.Given this new information, The ARIMA(2,1,0 to consider the ARIMA(2,1,0) model as the best 

Forecasting
```{R echo=FALSE, message=TRUE, warning=TRUE}


model1<- Arima(Can_month_housing_sell.ts, order=c(0,1,1))
model1_forecast <- forecast( model1, h = 12)
autoplot(model1_forecast) + 
  theme_fivethirtyeight() +
  labs(title = "Canadian housing resales", x = "Year", y = "housing sales") +
  labs(subtitle = "12 month forceast of model ARIMA (0,1,1)") + 
  theme(axis.title = element_text())

model1
  


```


The conditional forecasting
```{r The_conditional_forecasting_1, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
#The bank rate
Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2022, 12), frequency = 12)
Bank_rate_raw <- "v122530" #Financial market statistics, last Wednesday unless otherwise stated, Bank of Canada, monthly
Bank_rate.st <- get_cansim_vector(Bank_rate_raw, start_time = "2007/1/01", end_time = "2022/12/31")
Bank_rate_year.st <- year(Bank_rate.st$REF_DATE[1])
Bank_rate_month.st <- month(Bank_rate.st$REF_DATE[1])

#transfer data to the time series time
c(Bank_rate_year.st, Bank_rate_month.st)
Bank_rate.ts<- ts(Bank_rate.st$VALUE, start = c(Bank_rate_year.st, Bank_rate_month.st), freq = 12)

mean(Bank_rate.ts)

The_foresting_House <- cbind(Bank_rate.ts, Can_month_housing_sell.ts)

autoplot(The_foresting_House, facets=TRUE) + 
  theme_fivethirtyeight()

include.drift=TRUE

Bank_rate.ts_2 <- diff(diff(Bank_rate.ts))

station
#####
#The GDP data Canada [11124]; Seasonally adjusted at annual rates; 2012 constant prices; All industries
CA_GDP_ARIMA_raw <- "v65201483"
CA_GDP_ARIMA.st <- get_cansim_vector(CA_GDP_ARIMA_raw, start_time =  "2006/01/01", end_time = "2022/12/31")
CA_GDP_ARIMA_year.st <- year(CA_GDP_ARIMA.st$REF_DATE[1])
CA_GDP_ARIMA_month.st <- month(CA_GDP_ARIMA.st$REF_DATE[1])
#transfer data to the time series time
c(CA_GDP_ARIMA_year.st, CA_GDP_ARIMA_month.st)
CA_GDP_ARIMA.ts <-ts(CA_GDP_ARIMA.st$VALUE, start = c(CA_GDP_ARIMA_year.st, CA_GDP_ARIMA_month.st), freq = 12)
plot(CA_GDP_ARIMA.ts)
stationary_CA_GDP_ARIMA.ts <- 100 *diff(log(CA_GDP_ARIMA.ts), lag = 12)
autoplot(stationary_CA_GDP_ARIMA.ts)
#######

pure_evil <- 100*diff(log(Can_month_housing_sell.ts), lag = 12)


Housing_sell_Stationary_CPI.ts <- cbind(pure_evil, Stationary_CPI.ts)
autoplot(Housing_sell_Stationary_CPI.ts, facets = T)


# Lagged predictors. Test 0, 1, 2 or 3 lags.
BankRate <- cbind(
    BankRateLag0 = Housing_sell_Stationary_CPI.ts[,"Stationary_CPI.ts"],
    BankRateLag1 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Stationary_CPI.ts"], -1),
    BankRateLag2 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Stationary_CPI.ts"], -2),
    BankRateLag3 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Stationary_CPI.ts"], -3),
    BankRateLag4 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Stationary_CPI.ts"], -4),
    BankRateLag5 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Stationary_CPI.ts"], -5)) %>%
  head(NROW(Housing_sell_Stationary_CPI.ts))

# Restrict data so models use the same fitting period
fit1 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1], stationary=TRUE)
fit2 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1:2], stationary=TRUE)
fit3 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1:3], stationary=TRUE)
fit4 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1:4], stationary=TRUE)
fit5 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1:5], stationary=TRUE)

c(fit1[["aicc"]],fit2[["aicc"]],fit3[["aicc"]],fit4[["aicc"]],fit5[["aicc"]])

##
Stationary_CPI_stationary.ts <- window(Stationary_CPI.ts, start = c(2008, 1), end = c(2022, 12))


The_conditional_forecasting_1<- auto.arima(pure_evil, xreg = Stationary_CPI_stationary.ts) 

Stationary_CPI_ARIMA.ts <- numeric(length = 12)
for (i in 1:12) {
  Stationary_CPI_ARIMA.ts [i] <- 2000
}

#6.07866570

print(forecast(The_conditional_forecasting_1, h = 12, xreg = Stationary_CPI_ARIMA.ts))


autoplot(forecast(The_conditional_forecasting_1, h = 12, xreg = Stationary_CPI_ARIMA.ts))+
   theme_fivethirtyeight() + 
   xlab("Year") +
  ylab("percentage") +
  ggtitle("Forecasting of canadian housing resales") +
  labs(subtitle = "If the inflation stay at current level for 12 month")+
  theme(axis.title = element_text())





```


```{r}
nothing <- cbind(stationary_CA_GDP.ts, unemployment_rate.ts, Stationary_CPI.ts, Bank_rate.ts)
The_conditional_forecasting_1<- auto.arima(Can_month_housing_sell.ts, xreg = nothing) 
print(The_conditional_forecasting_1)
#######
new_bank_rate_ARIMA.ts <- numeric(length = 12)
for (i in 1:12) {
  new_bank_rate_ARIMA.ts[i] <- 4.5
}

stationary_CA_GDP_ARIMA.ts <- numeric(length = 12)
for (i in 1:12) {
  stationary_CA_GDP_ARIMA.ts[i] <- 2.36565785
}
unemployment_rate_ARIMA.ts <- numeric(length = 12)
for (i in 1:12) {
  unemployment_rate_ARIMA.ts[i] <- 5
}


Stationary_CPI_ARIMA.ts <- numeric(length = 12)
for (i in 1:12) {
  Stationary_CPI_ARIMA.ts [i] <- 2.07866570
}


nothing_2 <- cbind(stationary_CA_GDP_ARIMA.ts, unemployment_rate_ARIMA.ts, Stationary_CPI_ARIMA.ts, new_bank_rate_ARIMA.ts)



autoplot(forecast(The_conditional_forecasting_1, h = 12, xreg = nothing_2))



######


checkresiduals(The_conditional_forecasting_1)




```
What is the policy rate remain 4.5 for next 6 month? how it will impact the housing relae market
what if the policy go back to 2019 levl at 1.75


```{r The_conditional_forecasting_, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

new_bank_rate45 <- numeric(length = 12)
for (i in 1:12) {
  new_bank_rate45[i] <- 2.36565785
}
evil_forcast <- forecast(The_conditional_forecasting_1, h = 12, xreg = new_bank_rate45)


new_bank_rate175 <- numeric(length = 12)
for (i in 1:12) {
  new_bank_rate175[i] <- 2
}
evil_forcast_2 <- forecast(The_conditional_forecasting_1, h = 12, xreg = new_bank_rate175)


#GDP_canada_arima <- auto.arima(CA_GDP.ts)


autoplot(evil_forcast) + 
theme_fivethirtyeight() +
  labs(title = "Canadian housing resales", x = "Year", y = "housing sales") +
  labs(subtitle = "Policy rate at 4.5% for next 12 months") + 
  theme(axis.title = element_text())

 autoplot(evil_forcast_2) + 
   theme_fivethirtyeight() +
  labs(title = "Canadian housing resales", x = "Year", y = "housing sales") +
  labs(subtitle = "Policy rate at 1.75% for next 12 months") + 
  theme(axis.title = element_text())
 

 autoplot( Bank_rate.ts) + 
   theme_fivethirtyeight() +
  labs(title = "Canadian polise rate from 2007 to 2022", x = "Year", y = "rate") +
  theme(axis.title = element_text())

```



Part 2 VAR model 

For better understand and forecasting the reltionahup between the canadian housing relase and other macro economic data relative to the business cycle. I contrucede model include the bank rate, gdp and infaltion and unmpleotymenr rate



```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
Evil.begain <- "2007/01/01"
Evil.end <- "2022/12/31"


#The GDP data Canada [11124]; Seasonally adjusted at annual rates; 2012 constant prices; All industries
CA_GDP_raw <- "v65201483"
CA_GDP.st <- get_cansim_vector(CA_GDP_raw, start_time =  "2007/01/01", end_time = "2022/12/31")
CA_GDP_year.st <- year(CA_GDP.st$REF_DATE[1])
CA_GDP_month.st <- month(CA_GDP.st$REF_DATE[1])
#transfer data to the time series time
c(CA_GDP_year.st, CA_GDP_month.st)
CA_GDP.ts <-ts(CA_GDP.st$VALUE, start = c(CA_GDP_year.st, CA_GDP_month.st), freq = 12)
plot(CA_GDP.ts)
#autoplot(CA_GDP.ts)

#get the data form statistic Canada
unemployment_rate_raw <- "v2062815" #Unemployment rate (Percentage); Both sexes; 15 years and over; Estimate; SA, Monthly.
unemployment.st <- get_cansim_vector(unemployment_rate_raw, start_time = "2008/01/01", end_time = "2022/12/31")
unemployment_rate_year.st <- year(unemployment.st$REF_DATE[1])
unemployment_rate_month.st <- month(unemployment.st$REF_DATE[1])
#transfer data to the time series time
c(unemployment_rate_year.st, unemployment_rate_month.st)
unemployment_rate.ts<- ts(unemployment.st$VALUE, start = c(unemployment_rate_year.st, unemployment_rate_month.st), freq = 12)
#now its time series data!
#plot(unemployment_rate.ts)


#we are assuming we are in no late 2023/1/17 
#Consumer Price Index (CPI)
CPI_raw <- "v41690914" #Consumer Price Index, monthly, seasonally adjusted, monthly (2002=100) 
CPI.st <- get_cansim_vector(CPI_raw, start_time = "2007/01/01", end_time = "2022/12/31")
CPI_year.st <- year(CPI.st$REF_DATE[1])
CPI_month.st <- month(CPI.st$REF_DATE[1])
#transfer data to the time series time
c(CPI_year.st, CPI_month.st)
CPI.ts<- ts(CPI.st$VALUE, start = c(CPI_year.st, CPI_month.st), freq = 12)
#now its time series data!
#plot(CPI.ts)

#The bank rate 
Bank_rate_raw <- "v122530" #Financial market statistics, last Wednesday unless otherwise stated, Bank of Canada, monthly 
Bank_rate.st <- get_cansim_vector(Bank_rate_raw, start_time = "2008/01/01", end_time = "2022/12/31")
Bank_rate_year.st <- year(Bank_rate.st$REF_DATE[1])
Bank_rate_month.st <- month(Bank_rate.st$REF_DATE[1])

#transfer data to the time series time
c(Bank_rate_year.st, Bank_rate_month.st)
Bank_rate.ts<- ts(Bank_rate.st$VALUE, start = c(Bank_rate_year.st, Bank_rate_month.st), freq = 12)
#now its time series data!
#plot(Bank_rate.ts)

Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2022, 12), frequency = 12)



#we are assuming we are in no late 2023/1/17 
#New housing price index, monthly, monthly (Index, 201612=100) 
New_housing_price_index_raw <- "v111955442" 
New_housing_price_index.st <- get_cansim_vector(New_housing_price_index_raw, start_time = Evil.begain, end_time = Evil.end)
New_housing_price_index_year.st <- year(New_housing_price_index.st$REF_DATE[1])
New_housing_price_index_month.st <- month(New_housing_price_index.st$REF_DATE[1])
#transfer data to the time series time
c(New_housing_price_index_year.st, New_housing_price_index_month.st)
New_housing_price_index.ts<- ts(New_housing_price_index.st$VALUE, start = c(New_housing_price_index_year.st, New_housing_price_index_month.st), freq = 12)
#now its time series data!
#autoplot(New_housing_price_index.ts)




#The bank rate 
Bank_rate_raw <- "v122530" #Financial market statistics, last Wednesday unless otherwise stated, Bank of Canada, monthly 
Bank_rate.st <- get_cansim_vector(Bank_rate_raw, start_time = "2007/02/01", end_time = "2022/12/31")
Bank_rate_year.st <- year(Bank_rate.st$REF_DATE[1])
Bank_rate_month.st <- month(Bank_rate.st$REF_DATE[1])


```

```{r}
####################
#5.2 Variable Transformation########################################
  #5.2.1 stationary CA_GDP.ts 
stationary_CA_GDP.ts <- 100 *diff(log(CA_GDP.ts), lag = 12)
  #5.2.2 leacve unemployment rate as it is  unemployment_rate.ts
  #5.2.3 stationary CPI.0ts
  Stationary_CPI.ts<- 100 * diff(log(CPI.ts), lag = 12)
  #5.2.4 leave bank rate as it is
  #5.2.5 stationary the housing sell 
stationary_Can_month_housing_sell.ts <- 100*diff(log(Can_month_housing_sell.ts), lag = 12)
stationary_New_housing_price_index.ts <- 100*(diff(log(New_housing_price_index.ts), lag=12))

#5.2.5 put all data together
all_data <- cbind(stationary_Can_month_housing_sell.ts,stationary_CA_GDP.ts, unemployment_rate.ts, Stationary_CPI.ts, Bank_rate.ts)
#autoplot(all_data)
#The adjustment here

############################################################
```

```{r eval=FALSE, message=FALSE, include=FALSE}
VARselect(all_data, lag.max = 12, type="const")

checkresiduals(The_evil_model)


acf(residuals(The_evil_model)[,2])
acf(residuals(The_evil_model)[,3])
acf(residuals(The_evil_model)[,4])
acf(residuals(The_evil_model)[,5])
acf(residuals(The_evil_model)[,1])

```

```{R}
The_evil_model <- VAR(all_data, p = 3 ,type = "const")

checkresiduals()


```

```{R echo=FALSE, message=FALSE, warning=FALSE}
# 5.3 Granger Causality Tests

housing_gdp_causality <- causality(The_evil_model, cause = "stationary_CA_GDP.ts")
housing_unemployment_causality <- causality(The_evil_model, cause = "unemployment_rate.ts")
housing_CPI_causality <- causality(The_evil_model, cause = "Stationary_CPI.ts")
housing_bank_rate_causality <- causality(The_evil_model, cause = "Bank_rate.ts")


housing_bank_rate_causality <- causality(The_conditional_forecasting_1, cause = "Stationary_CPI_stationary.ts")


print(housing_gdp_causality)
print(housing_unemployment_causality)
print(housing_CPI_causality)
print(housing_bank_rate_causality)
```
interrdting enroughh that the unemploymetn rate has vey litter granfger causality test with the rest of data. 


```{r echo=FALSE}
#5.4 the root test
roots(The_evil_model)

# the root test show that the var is stable.

The_Var_model <- forecast(The_evil_model, h = 12)
# Extract the forecast for the 'stationary_Can_month_housing_sell.ts' variable
#print(The_Var_model$forecast$stationary_Can_month_housing_sell.ts)

autoplot(The_Var_model)


#autoplot(The_Var_model)
autoplot(The_Var_model$forecast$stationary_Can_month_housing_sell.ts) + 
   theme_fivethirtyeight() + 
  xlab("Year") +
  ylab("Housing Sell") +
  ggtitle("Canadian housing relace market forecast") + 
  labs(subtitle = "housing resales 12 months forecast") 

```

heel



```{r}

library(glmnet)

# Combine all time series into a single data frame

all_data <- cbind(stationary_Can_month_housing_sell.ts, stationary_CA_GDP.ts, unemployment_rate.ts, Stationary_CPI.ts, Bank_rate.ts)

data_combined <- data.frame(all_data)

colnames(data_combined) <- c("stationary_Can_month_housing_sell.ts", "stationary_CA_GDP.ts", "unemployment_rate.ts", "Stationary_CPI.ts", "Bank_rate.ts")

# Make sure all time series have the same length
data_combined <- na.omit(data_combined)

# Create a lagged version of Can_month_housing_sell.ts
lagged_Can_month_housing_sell <- c(NA, head(Can_month_housing_sell.ts, -1))

# Combine all time series into a single data frame
data_combined <- data.frame(CA_GDP.ts, unemployment_rate.ts, CPI.ts, Bank_rate.ts, New_housing_price_index.ts, Can_month_housing_sell.ts, lagged_Can_month_housing_sell)
colnames(data_combined) <- c("CA_GDP", "unemployment_rate", "CPI", "Bank_rate", "New_housing_price_index", "Can_month_housing_sell", "lagged_Can_month_housing_sell")

# Make sure all time series have the same length
data_combined <- na.omit(data_combined)
 

# Prepare the data for glmnet
x <- as.matrix(data_combined[, 1:5]) # predictors
y <- data_combined$lagged_Can_month_housing_sell # response variable

# LASSO regression with cross-validation
lasso_model <- cv.glmnet(x, y, alpha = 1, nfolds = 10)
plot(lasso_model)

# Ridge regression with cross-validation
ridge_model <- cv.glmnet(x, y, alpha = 0, nfolds = 10)
plot(ridge_model)



```






