---
output:
  pdf_document: default
  html_document: default
  latex_engine: xelatex
  word_document: default
fontsize: 12pt
mainfont: Times New Roman
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
alist( message=FALSE, warning=FALSE, paged.print=FALSE, echo=FALSE )
alist(message=FALSE, warning=FALSE, paged.print=FALSE, echo=FALSE)


```

loding the package
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(ggplot2)
library(fpp2)
library(glmnet)
library(tidyr)
library(lmtest)
library(boot)
library(forecast)
library(readr)
library(ggfortify)
library(tseries)
library(urca)
library(readxl)
library(lubridate)
library(cansim)
library(OECD)
library(WDI)
library(fredr)
library(tsbox)
library(RColorBrewer)
library(wesanderson)
library(writexl)
library(gridExtra)
library(vars)
library("ggthemes")
library(leaps)
```



loading the data
```{r message=FALSE, paged.print=FALSE}
#1.import the data
Can_housing_sell_data.raw <- read_excel("/Users/tie/Documents/GitHub/ECON-493-forcasting-economy/The research project/News_release_chart_data_mar_2023.xlsx", sheet = "Chart A", col_types = c("date",  "numeric", "numeric", "skip", "skip"))

#transfer data to ts form
Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023, 2), frequency = 12)
```

#The overall data and seasonal plot
```{r message=FALSE, warning=FALSE, paged.print=FALSE}

autoplot(Can_month_housing_sell.ts) +
theme_fivethirtyeight() +
xlab("Year") +
ylab("Housing Sales") +
ggtitle("Canadian Housing Resales from 2007 to 2023") +
theme(axis.title = element_text())

#1.1.2 the seasonal plot
Can_month_housing_sell_plot_ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2010, 1), end = c(2019, 1), frequency = 12)

#1.1.3 the seasonality graph
ggsubseriesplot(Can_month_housing_sell_plot_ts) +
ylab("Number of Homes Sold") +
theme_fivethirtyeight() +
xlab("Month") +
ylab("Housing Sales") +
ggtitle("Canadian Housing Resales Seasonality") +
labs(subtitle = "Housing resales are higher in the summer") +
theme(axis.title = element_text())



#plot the bank rate. 

 Bank_rate_1_ARIMA_raw <- "v122530" #Financial market statistics, last Wednesday unless otherwise stated, Bank of Canada, monthly
 Bank_rate_1_ARIMA.st <- get_cansim_vector( Bank_rate_1_ARIMA_raw, start_time = "2007/01/01")
 Bank_rate_1_ARIMA_year.st <- year( Bank_rate_1_ARIMA.st$REF_DATE[1])
 Bank_rate_1_ARIMA_month.st <- month( Bank_rate_1_ARIMA.st$REF_DATE[1])
 c(Bank_rate_1_ARIMA_year.st,  Bank_rate_1_ARIMA_month.st)

 Bank_rate_1_ARIMA.ts<- ts( Bank_rate_1_ARIMA.st$VALUE, start = c( Bank_rate_1_ARIMA_year.st,  Bank_rate_1_ARIMA_month.st), freq = 12)
 
 
autoplot(Bank_rate_1_ARIMA.ts) +
ylab("Policy rate") +
theme_fivethirtyeight() +
xlab("Month") +
ylab("rate") +
ggtitle("Policy rate set by Bank of Canada ") +
labs(subtitle = "from 2007 to 2023") +
theme(axis.title = element_text())


```

The part one: ARIMA
Lode all ARIMA combination data 
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

##### covid start at 2019/12 
##### 2008 recession end in 2008/07

#excel is way better on doing the covid dummy variable
The_covid_dummy <- read_excel("/Users/tie/Documents/GitHub/ECON-493-forcasting-economy/The research project/The covid dummy.xlsx", 
    col_types = c("skip", "numeric"))
```


```{r}
#construed model
#note: first I realize with those fancy settingmay help them I realize this is waste of time....

######## all data model
#The entire data
Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023, 2), frequency = 12)
The_covid_dummy_ARIMA.ts <- ts(The_covid_dummy, start = c(2007, 1), end = c(2023, 2), frequency = 12)

#moding time
all_data_model_1 <- auto.arima(Can_month_housing_sell.ts, approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                               num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                               start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                               max.d = 5, max.p = 5, max.q = 5)

all_data_model_2 <- auto.arima(Can_month_housing_sell.ts)

# all data plus dummy variable

all_data_dummy_1 <- auto.arima(Can_month_housing_sell.ts, xreg = The_covid_dummy_ARIMA.ts, approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                               num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                               start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                               max.d = 5, max.p = 5, max.q = 5, d = 1)
#Regression with ARIMA(2,1,0) errors 

all_data_dummy_2 <- auto.arima(Can_month_housing_sell.ts, xreg = The_covid_dummy_ARIMA.ts, d = 1) 

#print(all_data_dummy_2)
#Regression with ARIMA(0,1,1) errors 


```

```{r}
############ 

#The data set without 
after_2008_forecasting_data <- window(Can_month_housing_sell.ts, start= c(2009,7), end= c(2023,2))
The_covid_dummy_after_208.ts <- ts(The_covid_dummy, start = c(2009, 7), end = c(2023, 2), frequency = 12)


####### after_2008_forecasting_model_1
after_2008_forecasting_model_1 <- auto.arima(after_2008_forecasting_data, d = 1,
                                             approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                             num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                             start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                             max.d = 5, max.p = 5, max.q = 5)

after_2008_forecasting_model_2 <- auto.arima(after_2008_forecasting_data)



past_2008_dummy_1 <- auto.arima(after_2008_forecasting_data, d = 1, xreg = The_covid_dummy_after_208.ts,
                                             approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                             num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                             start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                             max.d = 5, max.p = 5, max.q = 5)
#print(past_2008_dummy_1)
#Regression with ARIMA(1,1,2) errors 

past_2008_dummy_2 <- auto.arima(after_2008_forecasting_data, xreg = The_covid_dummy_after_208.ts)

#print(past_2008_dummy_2)
#Regression with ARIMA(0,1,1) errors 

#I did do the ARIMA with Covid dummy variable but it does not including in the paper becuase cross validation does not work.
#it just keep tell me it cannot found model :(
#the three years before and after does not included within the paper..


```

```{r}

########## entire data without covid shock

#The data from 2007 to 2019 (the entire data without Covid shock)
Can_month_housing_sell_without_covid_shock.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2019, 1), frequency = 12)

##### model 


entil_data_without_covid_shock_1<- auto.arima(Can_month_housing_sell_without_covid_shock.ts, 
                                              approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                              num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                              start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                              max.d = 5, max.p = 5, max.q = 5)

entil_data_without_covid_shock_2 <- auto.arima(Can_month_housing_sell_without_covid_shock.ts)


```

```{r}
#########

#The data from 2008 to 2019 (After recession without covid shock)
after_2008_forecasting_without_covid_shock_data <- window(Can_month_housing_sell.ts, start= c(2009,7), end= c(2019, 1))


test_model_one_after_2008_forecasting_without_covid_shock_1 <- auto.arima(after_2008_forecasting_without_covid_shock_data,
                                                                          approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                                                          num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                                                          start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                                                          max.d = 5, max.p = 5, max.q = 5)


test_model_one_after_2008_forecasting_without_covid_shock_2 <- auto.arima(after_2008_forecasting_without_covid_shock_data)

```

```{r}

from_2007_to_2017 <- window(Can_month_housing_sell.ts, start= c(2007,1), end= c(2017, 1))

from_2007_to_2017_1 <- auto.arima(from_2007_to_2017,
                                  approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                  num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                  start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                  max.d = 5, max.p = 5, max.q = 5)

from_2007_to_2017_2 <- auto.arima(from_2007_to_2017)



```


```{R}
####################
# Create a data frame with the names and ARIMA models
ARIMA_models_table <- data.frame(
  ARIMA = c(as.character(all_data_model_1), 
            as.character(all_data_model_2), 
            as.character(after_2008_forecasting_model_1), 
            as.character(after_2008_forecasting_model_2),
            as.character(The_before_during_after_Covid_model_1), 
            as.character(The_before_during_after_Covid_model_2), 
            as.character(test_model_one_after_2008_forecasting_without_covid_shock_1),
            as.character(test_model_one_after_2008_forecasting_without_covid_shock_2),
            as.character(entil_data_without_covid_shock_1), 
            as.character(entil_data_without_covid_shock_2),
            as.character(from_2007_to_2017_1), 
            as.character(from_2007_to_2017_2))
)

# Print the table
print(ARIMA_models_table)
```


Trying to do the ARIMA with dummy variable
(its work! but no idea how to do cross validation of it)
give up on it

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

#maybe put some noise?
#generate the random noise
set.seed(123)
error <- rnorm(196, mean = 0, sd = 1)
error_evil <- (error - mean(error))*1/10
#make the noises smaller? 

#transfer the error data into the time series
error_evil.ts <- ts(error_evil, start = c(2007, 1), end = c(2023, 2), frequency = 12)

#The covid dummy variable
The_covid_dummy.raw <- ts(The_covid_dummy$Covid_dummy, start = c(2007, 1), end = c(2023, 2), frequency = 12)

#put them together!
The_covid_dummy.ts <- (error_evil.ts + The_covid_dummy.raw )


ARIMA_with_Covid_dummy <- auto.arima(Can_month_housing_sell.ts, xreg = The_covid_dummy.ts,  approximation = FALSE, parallel = TRUE, stepwise = FALSE, num.cores = 10, d = 1)
print(ARIMA_with_Covid_dummy)

# ARIMA(2,1,0).......
# Create future covid dummy for the next 12 months
covid_dummy_future <- numeric(length = 12)
for (i in 1:12) {
  covid_dummy_future[i] <- 0
}

# Convert covid_dummy_future to a time series object
covid_dummy_future.ts <- ts(covid_dummy_future, start = c(2023, 3), frequency = 12)

model_dummy_forecast <- forecast(ARIMA_with_Covid_dummy, xreg = covid_dummy_future.ts, h = 12)

autoplot(model_dummy_forecast)
#It does not make things better.
```


```{R echo=FALSE, message=FALSE, warning=FALSE}
ARIMA_model_table_2 <- data.frame(
  Model = c("ARIMA(2,1,0)",
            "ARIMA(0,1,1)", 
            "ARIMA(2,1,2)(0,0,1)[12]",
            "ARIMA(0,1,0)")
)
print(ARIMA_model_table_2)

```


Compare the AIC and BIC on data without covid_19 impact
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
#fit the model into the entire data.
Can_month_housing_sell_without_Covid.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2019, 1), frequency = 12)

# Fit the ARIMA(2,1,0) model
model1_Without_Covid<- Arima(Can_month_housing_sell_without_Covid.ts, order=c(2,1,0))

# Fit the ARIMA(0,1,1) model
model2_Without_Covid<- Arima(Can_month_housing_sell_without_Covid.ts, order=c(0,1,1))

# Fit the ARIMA(2,1,2)(0,0,1)[12] model with zero mean
model3_Without_Covid <- Arima(Can_month_housing_sell_without_Covid.ts, order=c(2,1,2), seasonal=list(order=c(0,0,1), period=12))

# Fit the ARIMA(0,1,0) mod
model4_Without_Covid <- Arima(Can_month_housing_sell_without_Covid.ts, order=c(0,1,0))



#4.3 AIC and BIC for data without covid.
AIC_and_BIC_Matrix_for_without_covid<- matrix (ncol = 2, nrow = 4)
colnames(AIC_and_BIC_Matrix_for_without_covid) <-c("AIC","BIC")
rownames(AIC_and_BIC_Matrix_for_without_covid) <-c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]", "ARIMA(0,1,0)")
AIC_and_BIC_Matrix_for_without_covid[1,1] <- AIC(model1_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[2,1] <- AIC(model2_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[3,1] <- AIC(model3_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[4,1] <- AIC(model4_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[1,2] <- BIC(model1_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[2,2] <- BIC(model2_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[3,2] <- BIC(model3_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[4,2] <- BIC(model4_Without_Covid)
print(AIC_and_BIC_Matrix_for_without_covid)

```


Compare the AIC and BIC on time data with covid impact
```{r echo=FALSE}
#fit the model into the entire data.
Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023, 2), frequency = 12)

# ARIMA(2,1,0) 
model1<- Arima(Can_month_housing_sell.ts, order=c(2,1,0))

# ARIMA(0,1,1)
model2<- Arima(Can_month_housing_sell.ts, order=c(0,1,1))

# ARIMA(2,1,2)(0,0,1)[12]
model3 <- Arima(Can_month_housing_sell.ts , order=c(2,1,2), seasonal=list(order=c(0,0,1), period=12))

# ARIMA(0,1,0)
model4<- Arima(Can_month_housing_sell.ts , order=c(0,1,0))

#AIC and BIC for the entire data
AIC_and_BIC_Matrix <- matrix (ncol = 2, nrow = 4)
colnames(AIC_and_BIC_Matrix) <-c("AIC","BIC")
rownames(AIC_and_BIC_Matrix) <-c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]", "ARIMA(0,1,0)")
AIC_and_BIC_Matrix[1,1] <- AIC(model1)
AIC_and_BIC_Matrix[2,1] <- AIC(model2)
AIC_and_BIC_Matrix[3,1] <- AIC(model3)
AIC_and_BIC_Matrix[4,1] <- AIC(model4)
AIC_and_BIC_Matrix[1,2] <- BIC(model1)
AIC_and_BIC_Matrix[2,2] <- BIC(model2)
AIC_and_BIC_Matrix[3,2] <- BIC(model3)
AIC_and_BIC_Matrix[4,2] <- BIC(model4)
print(AIC_and_BIC_Matrix)
```


Cross validation one 
The training set 2007 - 2015
the test set 2016 - 2018
```{r}

#put the data here so i will not forget!
Can_month_housing_sell_test.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023,1), frequency = 12)

#(2023 - 2018)
n.end <- 2016 #when the training set end
n_test <- 12 * 3 
# the training set end + how many month 
#这个要算上结束的年份！ n.end = 2016 意思的是测试是2016年开始。

n_models <- 4 #
h.val <- 1 # how many step forcast

#set the martix pred
pred <- matrix(rep(NA, n_test * (n_models + 1)), nrow=n_test, ncol=(n_models + 1)) 
#建立一个matrix，全部填NA，test行数和model列数。 

# the for loop
for (i in 1: n_test ) {
  tmp0 <- 2007 #the training start at 2007 
  tmp1 <- n.end + (i - 2) * (1/12) #the end of training windows 
  
  tmp <- window(Can_month_housing_sell_test.ts, start=tmp0, end=tmp1) 
  #the training data set from 2007 to the date to its en
  #2007 to 2016 + (observation windos)

  
#The real value
  pred[i, 1] <- window(Can_month_housing_sell.ts, start=tmp1 + (1/12), end=tmp1 + (1/12))
  
#moding time!
  fit1 <- Arima(tmp, order=c(2,1,0))
  fit2 <- Arima(tmp, order=c(0,1,1))
  fit3 <- Arima(tmp, order=c(2,1,2), seasonal=list(order=c(0,0,1), period=12))
  fit4 <- Arima(tmp, order=c(0,1,0))
  
#one step
  pred[i, 2] <- forecast(fit1, h= h.val)$mean[h.val]
  pred[i, 3] <- forecast(fit2, h= h.val)$mean[h.val]
  pred[i, 4] <- forecast(fit3, h= h.val)$mean[h.val]
  pred[i, 5] <- forecast(fit4, h= h.val)$mean[h.val]
}

#calculate the error

error <- (pred[, -1] - pred[, 1])
#pred[.-1] 除了第一列的所有减去第一列
#note here: pred[, -2] does not mean using all the value expect second one...
  #it mean delete all the second col!
  #I love matrix and matrix makes me happy

mse <- colMeans(error)
#reture the mean of coln

rmse <- sqrt(colMeans(error^2))
mae <- colMeans(abs(error))
mpe <- colMeans((error/ pred[, 1]) * 100)
mape <- colMeans(abs((error/ pred[, 1]) * 100))

#The outcome
The_evil_df <- data.frame(
  Model = c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]",  "ARIMA(0,1,0)"),
  ME = mse,
  RMSE = rmse,
  MAE = mae,
  MPE = mpe,
  MAPE = mape
)

print(The_evil_df)

```


Cross validation two
The training set: 2007 - 2020
The test set: 2020 - 2022
```{r echo=FALSE, paged.print=FALSE}

Can_month_housing_sell_test.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023,1), frequency = 12)

#(2023 - 2018)
n.end <- 2019
n_test <- 12 * 4#the times we need go
# the training set end + how many month 
#这个要算上结束的年份！ n.end = 2016 意思的是测试是2016年开始。

n_models <- 4 #
h.val <- 1 # how many step forcast

#set the martix pred
pred <- matrix(rep(NA, n_test * (n_models + 1)), nrow=n_test, ncol=(n_models + 1)) 
#建立一个matrix，全部填NA，test行数和model列数。 

# the for loop
for (i in 1: n_test ) {
  tmp0 <- 2007 #the training start at 2007 
  tmp1 <- n.end + (i - 2) * (1/12) #the end of training windows 
  
  tmp <- window(Can_month_housing_sell_test.ts, start=tmp0, end=tmp1) 
  #the training data set from 2007 to the date to its en
  #2007 to 2016 + (observation windos)

  
#The real value
  pred[i, 1] <- window(Can_month_housing_sell.ts, start=tmp1 + (1/12), end=tmp1 + (1/12))
  
#moding time!
  fit1 <- Arima(tmp, order=c(2,1,0))
  fit2 <- Arima(tmp, order=c(0,1,1))
  fit3 <- Arima(tmp, order=c(2,1,2), seasonal=list(order=c(0,0,1), period=12))
  fit4 <- Arima(tmp, order=c(0,1,0))
  
#one step
  pred[i, 2] <- forecast(fit1, h= h.val)$mean[h.val]
  pred[i, 3] <- forecast(fit2, h= h.val)$mean[h.val]
  pred[i, 4] <- forecast(fit3, h= h.val)$mean[h.val]
  pred[i, 5] <- forecast(fit4, h= h.val)$mean[h.val]
}

#calculate the error

error <- (pred[, -1] - pred[, 1])
#pred[.-1] 除了第一列的所有减去第一列
#note here: pred[, -2] does not mean using all the value expect second one...
  #it mean delete all the second col!
  #I love matrix and matrix makes me happy

mse <- colMeans(error)
#reture the mean of coln

rmse <- sqrt(colMeans(error^2))
mae <- colMeans(abs(error))
mpe <- colMeans((error/ pred[, 1]) * 100)
mape <- colMeans(abs((error/ pred[, 1]) * 100))

#The outcome
The_evil_df <- data.frame(
  Model = c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]",  "ARIMA(0,1,0)"),
  ME = mse,
  RMSE = rmse,
  MAE = mae,
  MPE = mpe,
  MAPE = mape
)

print(The_evil_df)



```


ARIMA (210) and ARIMA (011)
```{R echo=FALSE, message=TRUE, warning=TRUE}
model1<- Arima(Can_month_housing_sell.ts, order=c(2,1,0))
model1_forecast <- forecast(model1, h = 12)
autoplot(model1_forecast) + 
  theme_fivethirtyeight() +
  labs(title = "12-Month Forecast of Canadian Housing Resales",
       x = "Year",
       y = "Housing Sales") +
  labs(subtitle = "Forecasting Canadian Housing Resales Using ARIMA (2,1,0)") + 
  theme(axis.title = element_text())

model_evil<- Arima(Can_month_housing_sell.ts, order=c(0,1,1))
model1_forecast <- forecast(model_evil, h = 12)
autoplot(model1_forecast) + 
  theme_fivethirtyeight() +
  labs(title = "12-Month Forecast of Canadian Housing Resales",
       x = "Year",
       y = "Housing Sales") +
  labs(subtitle = "Forecasting Canadian Housing Resales Using ARIMA (0,1,1)") + 
  theme(axis.title = element_text())


```



from here to part 2 var forecasting are unused code.
you can just jump to part 2 var model....

The conditional forecasting 1 base on ARIMA but give up on it due to the frecasting almost same
```{r The_conditional_forecasting_1, message=FALSE, warning=FALSE, paged.print=FALSE}


Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2022, 12), frequency = 12)

 #V80691311
 Bank_rate_ARIMA_raw <- "v122530" #Financial market statistics, last Wednesday unless otherwise stated, Bank of Canada, monthly
 Bank_rate_ARIMA.st <- get_cansim_vector( Bank_rate_ARIMA_raw, start_time = "2008/01/01", end_time = "2022/12/31")
 Bank_rate_ARIMA_year.st <- year( Bank_rate_ARIMA.st$REF_DATE[1])
 Bank_rate_ARIMA_month.st <- month( Bank_rate_ARIMA.st$REF_DATE[1])
c( Bank_rate_ARIMA_year.st,  Bank_rate_ARIMA_month.st)

 Bank_rate_ARIMA.ts<- ts( Bank_rate_ARIMA.st$VALUE, start = c( Bank_rate_ARIMA_year.st, Bank_rate_ARIMA_month.st), freq = 12)
################
 
 

```


The conditional forecasting 2: The CPI with the bank rate (The plane B for the ARIMA forecasting)
```{r}

#we are assuming we are in no late 2023/1/17  
#Consumer Price Index (CPI)
CPI_ARIMA.raw <- "v41690914" #Consumer Price Index, monthly, seasonally adjusted, monthly (2002=100) 
CPI_ARIMA.st <- get_cansim_vector(CPI_ARIMA.raw, start_time = "2007/01/01", end_time = "2022/12/31")
CPI_ARIMA_year.st <- year(CPI_ARIMA.st$REF_DATE[1])
CPI_ARIMA_month.st <- month(CPI_ARIMA.st$REF_DATE[1])
#transfer data to the time series time
c(CPI_ARIMA_year.st, CPI_ARIMA_month.st)
CPI_ARIMA.ts<- ts(CPI_ARIMA.st$VALUE, start = c(CPI_ARIMA_year.st, CPI_ARIMA_month.st), freq = 12)
#now its time series data!
#plot(CPI.ts)
####
```



```{r}
Can_month_housing_sell_ARIMA.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2022, 12), frequency = 12)

###### station CPI and housing resale#
#stationary_CPI_ARIMA.ts <- (100 * diff(log(CPI_ARIMA.ts), lag = 12))
Stationary_housing_resale_ARIMA.ts <- 100* diff(log(Can_month_housing_sell_ARIMA.ts), lag = 12)
#adf.test(Stationary_housing_resale_ARIMA.ts)
Housing_sell_Stationary_CPI.ts <- cbind(Stationary_housing_resale_ARIMA.ts, Bank_rate_ARIMA.ts)
```


Try the lag test
```{r}
# The_lage_test
BankRate <- cbind(
  BankRateLag0 = Housing_sell_Stationary_CPI.ts[,"Bank_rate_ARIMA.ts"],
  BankRateLag1 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Bank_rate_ARIMA.ts"], 1),
  BankRateLag2 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Bank_rate_ARIMA.ts"], 2),
  BankRateLag3 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Bank_rate_ARIMA.ts"], 3),
  BankRateLag4 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Bank_rate_ARIMA.ts"], 4)
) %>% head(NROW(Housing_sell_Stationary_CPI.ts))

# Fit ARIMA models
fit1 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1], stationary=TRUE)
fit2 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1:2], stationary=TRUE)
fit3 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1:3], stationary=TRUE)
fit4 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1:4], stationary=TRUE)

# Show AICc values
cat("AICc values:", fit1[["aicc"]], fit2[["aicc"]], fit3[["aicc"]], fit4[["aicc"]], "\n")

#only lag one? 
#I spend 40 min it is only lag one? 
```


now is generate the dynamatic regression's acutally arima model.
```{r}

The_conditional_forecasting_2 <- auto.arima(Stationary_housing_resale_ARIMA.ts, xreg = Bank_rate_ARIMA.ts, stationary = T, approximation = FALSE, parallel = TRUE, stepwise = FALSE, num.cores = 10)

print(The_conditional_forecasting_2)
```


What if the policy rate remain 4.5 for next 12 month
```{R}

Stationary_Bank_ARIMA_forecasting_1.ts <- matrix(rep(4.5, times = 12), ncol = 1)


Stationary_Bank_ARIMA_forecast_1.ts <- matrix(rep(4.5, times = 12), ncol = 1)

autoplot(forecast(The_conditional_forecasting_2, 
                 h = 12, 
                 xreg = Stationary_Bank_ARIMA_forecast_1.ts)) +
  theme_fivethirtyeight() +
  xlab("Year") +
  ylab("Percentage") +
  ggtitle("Forecasting Year-over-Year Change") +
  labs(subtitle = "What Happens If the Policy Rate Stays at the Current Level of 4.5% for 12 Months?") +
  theme(axis.title = element_text())
#why is it not performing well?


#it not working very good?
#but why?
```

What if the policy rate remain 2 for next 12 month (the average in 2019)
```{r}
Stationary_Bank_ARIMA_forecasting_2.ts <- matrix(rep(2, times = 12), ncol = 1)


autoplot(forecast(The_conditional_forecasting_2, 
                 h = 12, 
                 xreg = Stationary_Bank_ARIMA_forecasting_2.ts)) +
  theme_fivethirtyeight() +
  xlab("Year") +
  ylab("Percentage") +
  ggtitle("Forecasting Year-over-Year Change") +
  labs(subtitle = "What Happens If the Policy Rate Stays at the Current Level of 2% for 12 Months?") +
  theme(axis.title = element_text())

#it not working very good?
#but why?

```



Part 2 VAR model 

First: data collection
```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

#Statistics Canada is pure evil!
Evil.begain <- "2007/01/01"
Evil.end <- "2022/12/31"

#The GDP data Canada [11124]; Seasonally adjusted at annual rates; 2012 constant prices; All industries
CA_GDP_raw <- "v65201483"
CA_GDP.st <- get_cansim_vector(CA_GDP_raw, start_time =  "2007/01/01", end_time = "2022/12/31")
CA_GDP_year.st <- year(CA_GDP.st$REF_DATE[1])
CA_GDP_month.st <- month(CA_GDP.st$REF_DATE[1])
#transfer data to the time series time
c(CA_GDP_year.st, CA_GDP_month.st)
CA_GDP.ts <-ts(CA_GDP.st$VALUE, start = c(CA_GDP_year.st, CA_GDP_month.st), freq = 12)
plot(CA_GDP.ts)
#autoplot(CA_GDP.ts)

#get the data form statistic Canada
unemployment_rate_raw <- "v2062815" #Unemployment rate (Percentage); Both sexes; 15 years and over; Estimate; SA, Monthly.
unemployment.st <- get_cansim_vector(unemployment_rate_raw, start_time = "2008/01/01", end_time = "2022/12/31")
unemployment_rate_year.st <- year(unemployment.st$REF_DATE[1])
unemployment_rate_month.st <- month(unemployment.st$REF_DATE[1])
#transfer data to the time series time
c(unemployment_rate_year.st, unemployment_rate_month.st)
unemployment_rate.ts<- ts(unemployment.st$VALUE, start = c(unemployment_rate_year.st, unemployment_rate_month.st), freq = 12)
#now its time series data!
#plot(unemployment_rate.ts)

#we are assuming we are in no late 2023/1/17 
#Consumer Price Index (CPI)
CPI_raw <- "v41690914" #Consumer Price Index, monthly, seasonally adjusted, monthly (2002=100) 
CPI.st <- get_cansim_vector(CPI_raw, start_time = "2007/01/01", end_time = "2022/12/31")
CPI_year.st <- year(CPI.st$REF_DATE[1])
CPI_month.st <- month(CPI.st$REF_DATE[1])
#transfer data to the time series time
c(CPI_year.st, CPI_month.st)
CPI.ts<- ts(CPI.st$VALUE, start = c(CPI_year.st, CPI_month.st), freq = 12)
#now its time series data!
#plot(CPI.ts)

####
#The bank rate 
Bank_rate_raw <- "v122530" #Financial market statistics, last Wednesday unless otherwise stated, Bank of Canada, monthly 
Bank_rate.st <- get_cansim_vector(Bank_rate_raw, start_time = "2008/01/01", end_time = "2022/12/31")
Bank_rate_year.st <- year(Bank_rate.st$REF_DATE[1])
Bank_rate_month.st <- month(Bank_rate.st$REF_DATE[1])

#transfer data to the time series time
c(Bank_rate_year.st, Bank_rate_month.st)
Bank_rate.ts<- ts(Bank_rate.st$VALUE, start = c(Bank_rate_year.st, Bank_rate_month.st), freq = 12)
#now its time series data!
#plot(Bank_rate.ts)

Can_month_housing_sell_var<- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2022, 12), frequency = 12)

#########
#we are assuming we are in no late 2023/1/17 
#New housing price index, monthly, monthly (Index, 201612=100) 
New_housing_price_index_raw <- "v111955442" 
New_housing_price_index.st <- get_cansim_vector(New_housing_price_index_raw, start_time = "2006/01/01", end_time = Evil.end)
New_housing_price_index_year.st <- year(New_housing_price_index.st$REF_DATE[1])
New_housing_price_index_month.st <- month(New_housing_price_index.st$REF_DATE[1])
#transfer data to the time series time
c(New_housing_price_index_year.st, New_housing_price_index_month.st)
New_housing_price_index.ts<- ts(New_housing_price_index.st$VALUE, start = c(New_housing_price_index_year.st, New_housing_price_index_month.st), freq = 12)
#now its time series data!
#autoplot()
New_housing_price_index_VAR.raw <- 100* diff(log(New_housing_price_index.ts), lag = 12)
new_housing_price_index_VAR.ts <- window(New_housing_price_index_VAR.raw, start= c(2008,1), end= c(2022,12))



#####
Can_month_housing_sell_var.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2022, 12), frequency = 12)
##########

#### The housing price index

The_housing_price<- read_excel("/Users/tie/Documents/GitHub/ECON-493-forcasting-economy/The research project/News_release_chart_data_mar_2023.xlsx", 
    sheet = "Chart 4", col_types = c("date", "skip",  "numeric", "numeric", "text"))

The_housing_price_raw.ts <- ts(The_housing_price$`MLS® HPI Aggregate Composite Benchmark†`, start = c(2005, 1), end = c(2023, 2), frequency = 12)


adf.test(The_housing_price_VAR_stationary.raw)

#the housing price graphy!
autoplot(The_housing_price_raw.ts) +
 theme_fivethirtyeight() +
  xlab("Year") +
  ylab("Percentage") +
  ggtitle("Housing price index") +
  labs(subtitle = "MLS® HPI Aggregate Composite Benchmark") +
  theme(axis.title = element_text())



```


```{r echo=FALSE}

#Variable Transformation########################################
  #5.2.1 stationary CA_GDP.ts 
stationary_CA_GDP.ts <- 100 *diff(log(CA_GDP.ts), lag = 12)
  #5.2.2 leacve unemployment rate as it is 
      #unemployment_rate.ts
  #5.2.3 stationary CPI.ts
  Stationary_CPI.ts<- 100 * diff(log(CPI.ts), lag = 12)
  #5.2.4 leave bank rate as it is
  #5.2.5 stationary the housing sell 
stationary_Can_month_housing_sell.ts <- 100*diff(log(Can_month_housing_sell_var.ts), lag = 12)
  #stationary the housing price index 
  The_housing_price_VAR_stationary.raw <-100* diff(log(The_housing_price_raw.ts), lag = 12)
  #cut to the suitable size
    HPI <- window(The_housing_price_VAR_stationary.raw, start= c(2008,1), end= c(2022,12))
  

  #The prime rate 
    #note: something went wrong on it
    

#5.2.5 put all data together
all_data <- cbind(stationary_CA_GDP.ts, Stationary_CPI.ts, HPI, new_housing_price_index_VAR.ts, Bank_rate.ts, unemployment_rate.ts)

```


doing the best subselection
why? because var model crashed....
```{r message=FALSE, warning=FALSE, paged.print=FALSE， echo=FALSE}


#stationary_Can_month_housing_sell.ts

# Transfer data into the df
Best_subselect<- cbind(stationary_CA_GDP.ts, Stationary_CPI.ts, HPI, new_housing_price_index_VAR.ts, unemployment_rate.ts, Bank_rate.ts)

all_data_df <- data.frame(Best_subselect)


# Select specific columns from all_data_df
# need to using short verson of name...

x <- all_data_df %>%
  dplyr::select(
   SGDP = stationary_CA_GDP.ts,
   SCPI =  Stationary_CPI.ts,
   HPI,
   UI = unemployment_rate.ts,
   BK =  Bank_rate.ts
  ) %>%
  data.matrix()

data2 <- data.frame(x, stationary_Can_month_housing_sell.ts)



#best subset selection time!
regfit.all <- regsubsets(stationary_Can_month_housing_sell.ts~ ., data = data2, nvmax = 100, method = "exhaustive")
reg.summary <- summary(regfit.all)
print(reg.summary)


# Plot results
par(mfrow = c(1, 3))
plot(reg.summary$rss, xlab = "Number of Variables", ylab = "SSR", type = "l")
m.rss <- which.min(reg.summary$rss)
points(m.rss, reg.summary$rss[m.rss], col = "green", cex = 2, pch = 20)
plot(reg.summary$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
m.bic <- which.min(reg.summary$bic)
points(m.bic, reg.summary$bic[m.bic], col = "green", cex = 2, pch = 20)
plot(reg.summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
m.cp <- which.min(reg.summary$cp)
points(m.cp, reg.summary$cp[m.cp], col = "green", cex = 2, pch = 20)
layout(1)

# Plot the regfit.all object with BIC
plot(regfit.all, scale = "bic", title = "best subset selection") 
#not working?


#transfer the data into number because time series does not working with it....
#妈耶救救孩子

y_numeric <- as.numeric(stationary_Can_month_housing_sell.ts)


# Fit lasso model
# Why lasso? 
# Because it can forcase some variable to zero...

lasso.mod <- glmnet(x, y_numeric, alpha = 1, lambda = 100^seq(3, -3, length = 1000))

# graphy time?
#I have no idea why we need this grpahy? 
#所以为啥要这个图？
#autoplot(lasso.mod, xvar = "lambda", label = TRUE)

# 5 fold cross validation for lasso...
lasso.cv <- cv.glmnet(x, y_numeric, alpha = 1, nfolds = 5)

#using the the smalled to fit thegrahy....
model3 <- glmnet(x, y_numeric, alpha = 1, lambda = lasso.cv$lambda.min)

# lasso! lasso! lasso!
coef3 <- coef(model3)


print(coef3)
# only one variable? 
# only one? 

```

#The backward search suggest that SCPIand HP are variable been picked


```{r echo=FALSE}

#base on the cauality test pick the best variable for further evoluation.

#the Var data
Var_all_data <- cbind(stationary_Can_month_housing_sell.ts, Stationary_CPI.ts, HPI, stationary_CA_GDP.ts, unemployment_rate.ts)


#leg selection
#VARselect(Var_all_data, type="const", lag.max = 11)
var_model_test <- VAR(Var_all_data, p = 3, type="const")
#roots(var_model)
#serial.test(var_model_test, lags.pt = 10, type = "PT.asymptotic")



# doing the granger test....
housing_CPI_pvalue <- causality(var_model_test, cause = "Stationary_CPI.ts")$Granger$p.value
housing_houing_price_pvalue <- causality(var_model_test, cause = "HPI")$Granger$p.value
housing_gdp_pvalue <- causality(var_model_test, cause = "stationary_CA_GDP.ts")$Granger$p.value
housing_unemployment_pvalue <- causality(var_model_test, cause = "unemployment_rate.ts")$Granger$p.value

# put the p value into the matrix
pv_matrix <- matrix(c(housing_CPI_pvalue, 
                      housing_houing_price_pvalue, 
                      housing_gdp_pvalue, 
                      housing_unemployment_pvalue), 
                    nrow = 1, ncol = 4, byrow = TRUE)

# Set the column names of the matrix
colnames(pv_matrix) <- c("CPI", "HPI", "GDP", "Unemployment")
rownames(pv_matrix) <- c("p-value")

# Print the matrix
print(pv_matrix)




```


```{r echo=FALSE}

Var_final_data <- cbind(stationary_Can_month_housing_sell.ts, Stationary_CPI.ts, HPI, stationary_CA_GDP.ts)

#The covid dummy variable
The_covid_dummy_VAR.ts <- ts(The_covid_dummy$Covid_dummy, start = c(2008, 1), end = c(2022, 12), frequency = 12)
 
#put bank rate with covid dummy variable together.
exogen_variable <- cbind(The_covid_dummy_VAR.ts, Bank_rate.ts)

#we can see how the bank rate and covid dummy variable impact on the entire housing resale market.


VARselect(Var_final_data, exogen = exogen_variable,  type="const", lag.max = 11)

var_final <- VAR(Var_final_data, exogen = exogen_variable, p = 3, type="const")

serial.test(var_final, lags.pt = 10, type = "PT.asymptotic")



###ready for the dummy varialbe

### The forecasting
The_future_covid_dummy.ts <-ts(rep(0, 12), start = c(2022, 12), frequency = 12)

#The bank rate set at 2% 
Bank_rate_1  <-ts(rep(2, 12), start = c(2022, 12), frequency = 12)

#The bank rate set at 4.5%
Bank_rate_2  <-ts(rep(4.5, 12), start = c(2022, 12), frequency = 12)


##########
Var_exogen_one <- as.matrix(cbind(The_future_covid_dummy.ts, Bank_rate_1)) 

##########
Var_exogen_two <- cbind(The_future_covid_dummy.ts, Bank_rate_2)


######## now its conditonal forecasting
#forget to change the colname

colnames(Var_exogen_one) <- colnames(exogen_variable)
colnames(Var_exogen_two) <- colnames(exogen_variable)


#forecasting_Time!
Var_forecasting_one <- forecast(var_final, dumvar = Var_exogen_one , h = 12 )

Var_forecasting_two <- forecast(var_final, dumvar = Var_exogen_two , h = 12)

# Print the results
autoplot(Var_forecasting_one$forecast$stationary_Can_month_housing_sell.ts) +
  theme_fivethirtyeight() +
  xlab("Year") +
  ylab("Percentage") +
  ggtitle("VAR Forecasting Year-over-Year Change") +
  labs(subtitle = "What Happens If the Policy Rate Stays at of 2% for 12 Months?") +
  theme(axis.title = element_text())



autoplot(Var_forecasting_two$forecast$stationary_Can_month_housing_sell.ts)+
 theme_fivethirtyeight() +
  xlab("Year") +
  ylab("Percentage") +
  ggtitle("VAR Forecasting Year-over-Year Change") +
  labs(subtitle = "What Happens If the Policy Rate Stays at the Current Level of 4.5% for 12 Months?") +
  theme(axis.title = element_text())


```




now, I can finally rest in the peace

Tie Ma
2023/04/15



