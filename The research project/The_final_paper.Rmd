---
output:
  word_document: default
  html_document: default
  latex_engine: xelatex
  pdf_document: default
fontsize: 12pt
mainfont: Times New Roman
---
loding the package
```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(ggplot2)
library(fpp2)
library(glmnet)
library(tidyr)
library(lmtest)
library(boot)
library(forecast)
library(readr)
library(ggfortify)
library(tseries)
library(urca)
library(readxl)
library(lubridate)
library(cansim)
library(OECD)
library(WDI)
library(fredr)
library(tsbox)
library(RColorBrewer)
library(wesanderson)
library(writexl)
library(gridExtra)
library(vars)
library("ggthemes")
```



loading the data
```{r message=FALSE, include=FALSE, paged.print=FALSE}
#1.import the data
Can_housing_sell_data.raw <- read_excel("/Users/tie/Documents/GitHub/ECON-493-forcasting-economy/The research project/News_release_chart_data_mar_2023.xlsx", sheet = "Chart A", col_types = c("date",  "numeric", "numeric", "skip", "skip"))

#transfer data to ts form
Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023, 2), frequency = 12)
```

#The overall data and seasonal plot
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
autoplot(Can_month_housing_sell.ts) +
   theme_fivethirtyeight() + 
   xlab("Year") +
  ylab("Housing Sell") +
  ggtitle("Canaidan housing resales from 2007 to 2023") +
   theme(axis.title = element_text())

  

#1.1.2 the seaonal plot
#Can_month_housing_sell_plot_ts<- ts(Can_housing_sell_data.raw$Canada, start = c(2010, 1), end = c(2019, 1), frequency = 12)

#1.1.3 the seasonality graphy
ggsubseriesplot(Can_month_housing_sell_plot_ts) +
  ylab("number of home saled") +
   theme_fivethirtyeight() +
   xlab("month") +
  ylab("Housing Sell") +
  ggtitle("Canadian housing resales Sesaonal") +
  labs(subtitle = "housing resales are higher in the summary") + 
  theme(axis.title = element_text())


#stationary_CA_GDP.ts

#autoplot(stationary_CA_GDP.ts) +
#   theme_fivethirtyeight() + 
#   xlab("Year") +
#  ylab("percentage") +
#  ggtitle("Canadian norminal GDP growth rate (2002 = 100)") +
 #  theme(axis.title = element_text())




```

Lode all ARIMA combination data 
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
#data
#The entire data 
Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023, 2), frequency = 12)
The_covid_dummy.ts <- ts(The_covid_dummy, start = c(2007, 1), end = c(2023, 2), frequency = 12)

#The data set without 2008
after_2008_forecasting_data <- window(Can_month_housing_sell.ts, start= c(2009,7), end= c(2023,2))
The_covid_dummy_after_208.ts <- ts(The_covid_dummy, start = c(2009, 7), end = c(2023, 2), frequency = 12)

#the Data from 2016 to 2023
The_before_during_after_Covid_model.data<-window(Can_month_housing_sell.ts, start= c(2016,1), end= c(2023,2))

#The data from 2007 to 2019 (the entire data without Covid shock)
Can_month_housing_sell_without_covid_shock.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2019, 1), frequency = 12)

#The data from 2008 to 2019 (After recession without covid shock)
after_2008_forecasting_without_covid_shock_data <- window(Can_month_housing_sell.ts, start= c(2009,7), end= c(2019, 1))

from_2007_to_2017 <- window(Can_month_housing_sell.ts, start= c(2007,1), end= c(2017, 1))
  

```


```{r}
#construed model
edall_data_model_1 <- auto.arima(Can_month_housing_sell.ts, approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                               num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                               start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                               max.d = 5, max.p = 5, max.q = 5)


all_data_model_2 <- auto.arima(Can_month_housing_sell.ts)

after_2008_forecasting_model_1 <- auto.arima(after_2008_forecasting_data, d = 1,
                                             approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                             num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                             start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                             max.d = 5, max.p = 5, max.q = 5)

after_2008_forecasting_model_2 <- auto.arima(after_2008_forecasting_data)

The_before_during_after_Covid_model_1 <- auto.arima(The_before_during_after_Covid_model.data, d = 1,
                                                    approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                                    num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                                    start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                                    max.d = 5, max.p = 5, max.q = 5)

The_before_during_after_Covid_model_2 <- auto.arima(The_before_during_after_Covid_model.data, d=1)

entil_data_without_covid_shock_1<- auto.arima(Can_month_housing_sell_without_covid_shock.ts, 
                                              approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                              num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                              start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                              max.d = 5, max.p = 5, max.q = 5)

test_model_one_after_2008_forecasting_without_covid_shock_1 <- auto.arima(after_2008_forecasting_without_covid_shock_data,
                                                                          approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                                                          num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                                                          start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                                                          max.d = 5, max.p = 5, max.q = 5)

entil_data_without_covid_shock_2 <- auto.arima(Can_month_housing_sell_without_covid_shock.ts)

test_model_one_after_2008_forecasting_without_covid_shock_2 <- auto.arima(after_2008_forecasting_without_covid_shock_data)

from_2007_to_2017_1 <- auto.arima(from_2007_to_2017,
                                  approximation = FALSE, parallel = TRUE, stepwise = FALSE,
                                  num.cores = 10, start.p = 0, start.q = 0, start.P = 0, 
                                  start.Q = 0, max.Q = 5, max.P = 5, max.D = 5,
                                  max.d = 5, max.p = 5, max.q = 5)

from_2007_to_2017_2 <- auto.arima(from_2007_to_2017)


####################
# Create a data frame with the names and ARIMA models
models_table <- data.frame(
  ARIMA = c(as.character(all_data_model_1), as.character(all_data_model_2), as.character(after_2008_forecasting_model_1), as.character(after_2008_forecasting_model_2),
            as.character(The_before_during_after_Covid_model_1), as.character(The_before_during_after_Covid_model_2), as.character(test_model_one_after_2008_forecasting_without_covid_shock_1),
            as.character(test_model_one_after_2008_forecasting_without_covid_shock_2), as.character(entil_data_without_covid_shock_1), as.character(entil_data_without_covid_shock_2),
            as.character(from_2007_to_2017_1), as.character(from_2007_to_2017_2))
)

# Print the table
print(models_table)
```


Trying to do the ARIMA with dummy variable
(its work! but no idea how to do cross validation of it)
give up on it

```{r}


#generate the random noise
set.seed(123)
error <- rnorm(196, mean = 0, sd = 1)
error_evil <- (error - mean(error))*1/10
#make the noises smaller? 

#transfer the error data into the time series
error_evil.ts <- ts(error_evil, start = c(2007, 1), end = c(2023, 2), frequency = 12)

#The covid dummy variable
The_covid_dummy.raw <- ts(The_covid_dummy$Covid_dummy, start = c(2007, 1), end = c(2023, 2), frequency = 12)

#put them together!
The_covid_dummy.ts <- (error_evil.ts + The_covid_dummy.raw )


#draw the graphy
plot(cd.ts)


ARIMA_with_Covid_dummy <- auto.arima(Can_month_housing_sell.ts, xreg = The_covid_dummy.ts,  approximation = FALSE, parallel = TRUE, stepwise = FALSE, num.cores = 10, d = 1)
print(ARIMA_with_Covid_dummy)



# Create future covid dummy for the next 12 months
covid_dummy_future <- numeric(length = 12)
for (i in 1:12) {
  covid_dummy_future[i] <- 0
}

# Convert covid_dummy_future to a time series object
covid_dummy_future.ts <- ts(covid_dummy_future, start = c(2023, 3), frequency = 12)


model_dummy_forecast <- forecast(ARIMA_with_Covid_dummy, xreg = covid_dummy_future.ts, h = 12)

autoplot(model_dummy_forecast)
```




```{R echo=FALSE, message=FALSE, warning=FALSE}
model_table_2 <- data.frame(
  Model = c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]", "ARIMA(0,1,0)")
)
print(model_table_2)

```


Compare the AIC and BIC on time data iwhtout covid impact
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
#fit the model into the entire data.
Can_month_housing_sell_without_Covid.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2019, 1), frequency = 12)

# Fit the ARIMA(2,1,0) model
model1_Without_Covid<- Arima(Can_month_housing_sell_without_Covid.ts, order=c(2,1,0))

# Fit the ARIMA(0,1,1) model
model2_Without_Covid<- Arima(Can_month_housing_sell_without_Covid.ts, order=c(0,1,1))

# Fit the ARIMA(2,1,2)(0,0,1)[12] model with zero mean
model3_Without_Covid <- Arima(Can_month_housing_sell_without_Covid.ts, order=c(2,1,2), seasonal=list(order=c(0,0,1), period=12))

# Fit the ARIMA(0,1,0) model
model4_Without_Covid <- Arima(Can_month_housing_sell_without_Covid.ts, order=c(0,1,0))



#4.3 AIC and BIC for data without covid.
AIC_and_BIC_Matrix_for_without_covid<- matrix (ncol = 2, nrow = 4)
colnames(AIC_and_BIC_Matrix_for_without_covid) <-c("AIC","BIC")
rownames(AIC_and_BIC_Matrix_for_without_covid) <-c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]", "ARIMA(0,1,0)")
AIC_and_BIC_Matrix_for_without_covid[1,1] <- AIC(model1_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[2,1] <- AIC(model2_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[3,1] <- AIC(model3_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[4,1] <- AIC(model4_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[1,2] <- BIC(model1_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[2,2] <- BIC(model2_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[3,2] <- BIC(model3_Without_Covid)
AIC_and_BIC_Matrix_for_without_covid[4,2] <- BIC(model4_Without_Covid)
print(AIC_and_BIC_Matrix_for_without_covid)

```


Compare the AIC and BIC on time data with covid impact
```{r echo=FALSE}
#fit the model into the entire data.
Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023, 2), frequency = 12)

# Fit the ARIMA(2,1,0) model
model1<- Arima(Can_month_housing_sell.ts, order=c(2,1,0))

# Fit the ARIMA(0,1,1) model
model2<- Arima(Can_month_housing_sell.ts, order=c(0,1,1))

# Fit the ARIMA(2,1,2)(0,0,1)[12] model with zero mean
model3 <- Arima(Can_month_housing_sell.ts , order=c(2,1,2), seasonal=list(order=c(0,0,1), period=12))

# Fit the ARIMA(0,1,0) model
model4<- Arima(Can_month_housing_sell.ts , order=c(0,1,0))

#AIC and BIC for the entire data
AIC_and_BIC_Matrix <- matrix (ncol = 2, nrow = 4)
colnames(AIC_and_BIC_Matrix) <-c("AIC","BIC")
rownames(AIC_and_BIC_Matrix) <-c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]", "ARIMA(0,1,0)")
AIC_and_BIC_Matrix[1,1] <- AIC(model1)
AIC_and_BIC_Matrix[2,1] <- AIC(model2)
AIC_and_BIC_Matrix[3,1] <- AIC(model3)
AIC_and_BIC_Matrix[4,1] <- AIC(model4)
AIC_and_BIC_Matrix[1,2] <- BIC(model1)
AIC_and_BIC_Matrix[2,2] <- BIC(model2)
AIC_and_BIC_Matrix[3,2] <- BIC(model3)
AIC_and_BIC_Matrix[4,2] <- BIC(model4)
print(AIC_and_BIC_Matrix)
```


Cross validation one 
The training set 2007 - 2015
the test set 2016 - 2018
```{r}

Can_month_housing_sell_test.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023,1), frequency = 12)

#(2023 - 2018)
n.end <- 2016
n_test <- 12 * 3
n_models <- 4
h.val <- 1 

#set the martix pred
pred <- matrix(rep(NA, n_test * (n_models + 1)), nrow=n_test, ncol=(n_models + 1)) 

# the for loop
for (i in 1: n_test ) {
  tmp0 <- 2007 #the training start at 2007 
  tmp1 <- n.end + (i - 2) * (1/12) #the end of training windows 
  tmp <- window(Can_month_housing_sell_test.ts, start=tmp0, end=tmp1) 
  #the training data set from 2007 to the date to its en
  #2007 to 2016 + (observation windos)

  
#The acutally value
  pred[i, 1] <- window(Can_month_housing_sell.ts, start=tmp1 + (1/12), end=tmp1 + (1/12))
  
#moding time!
  fit1 <- Arima(tmp, order=c(2,1,0))
  fit2 <- Arima(tmp, order=c(0,1,1))
  fit3 <- Arima(tmp, order=c(2,1,2), seasonal=list(order=c(0,0,1), period=12))
  fit4 <- Arima(tmp, order=c(0,1,0))
  
#one step
  pred[i, 2] <- forecast(fit1, h= h.val)$mean[h.val]
  pred[i, 3] <- forecast(fit2, h= h.val)$mean[h.val]
  pred[i, 4] <- forecast(fit3, h= h.val)$mean[h.val]
  pred[i, 5] <- forecast(fit4, h= h.val)$mean[h.val]
}

#calculate the error

error <- (pred[, -1] - pred[, 1])
mse <- colMeans(error)
rmse <- sqrt(colMeans(error^2))
mae <- colMeans(abs(error))
mpe <- colMeans((error/ pred[, 1]) * 100)
mape <- colMeans(abs((error/ pred[, 1]) * 100))

#The outcome
The_evil_df <- data.frame(
  Model = c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]",  "ARIMA(0,1,0)"),
  ME = mse,
  RMSE = rmse,
  MAE = mae,
  MPE = mpe,
  MAPE = mape
)

print(The_evil_df)

```


Cross validation two
The training set: 2007 - 2020
The test set: 2020 - 2022
```{r echo=FALSE, paged.print=FALSE}

Can_month_housing_sell_test.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2023,1), frequency = 12)

#(2023 - 2018)
n.end <- 2019
n_test <- 12 * 4#the times we need go
n_models <- 4  
h.val <- 1 

#set the martix pred
pred <- matrix(rep(NA, n_test * (n_models + 1)), nrow=n_test, ncol=(n_models + 1)) 

# the for loop
for (i in 1: n_test ) {
  tmp0 <- 2007 #the training start at 2007 
  tmp1 <- n.end + (i - 2) * (1/12) #the end of training windows 
  tmp <- window(Can_month_housing_sell_test.ts, start=tmp0, end=tmp1) 
  #the training data set from 2007 to the date to its end
  #2007 to 2016 + (observation windos)

  
#The acutally value
  pred[i, 1] <- window(Can_month_housing_sell.ts, start=tmp1 + (1/12), end=tmp1 + (1/12))
  
#moding time!
  fit1 <- Arima(tmp, order=c(2,1,0))
  fit2 <- Arima(tmp, order=c(0,1,1))
  fit3 <- Arima(tmp, order=c(2,1,2), seasonal=list(order=c(0,0,1), period=12))
  fit4 <- Arima(tmp, order=c(0,1,0))
  
#one step
  pred[i, 2] <- forecast(fit1, h= h.val)$mean[h.val]
  pred[i, 3] <- forecast(fit2, h= h.val)$mean[h.val]
  pred[i, 4] <- forecast(fit3, h= h.val)$mean[h.val]
  pred[i, 5] <- forecast(fit4, h= h.val)$mean[h.val]
}

#calculate the error

error <- (pred[, -1] - pred[, 1])
mse <- colMeans(error)
rmse <- sqrt(colMeans(error^2))
mae <- colMeans(abs(error))
mpe <- colMeans((error/ pred[, 1]) * 100)
mape <- colMeans(abs((error/ pred[, 1]) * 100))

#The outcome
The_evil_df <- data.frame(
  Model = c("ARIMA(2,1,0)", "ARIMA(0,1,1)", "ARIMA(2,1,2)(0,0,1)[12]",  "ARIMA(0,1,0)"),
  ME = mse,
  RMSE = rmse,
  MAE = mae,
  MPE = mpe,
  MAPE = mape
)

print(The_evil_df)


```



```{R echo=FALSE, message=TRUE, warning=TRUE}
model1<- Arima(Can_month_housing_sell.ts, order=c(2,1,0))
model1_forecast <- forecast( model1, h = 12)
autoplot(model1_forecast) + 
  theme_fivethirtyeight() +
  labs(title = "Canadian housing resales", x = "Year", y = "housing sales") +
  labs(subtitle = "12 month forceast of model ARIMA (2,1,0)") + 
  theme(axis.title = element_text())

```



The conditional forecasting 1 the bank 
```{r The_conditional_forecasting_1, message=FALSE, warning=FALSE, paged.print=FALSE}

# I did not using this one? 
# Because no idea how to deal with policy rate.....

#The conditional forecast one: The bank rate with Canadian housing resale.
#################The bank rate
Can_month_housing_sell.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2022, 12), frequency = 12)


 #V80691311

 Bank_rate_ARIMA_raw <- "v122530" #Financial market statistics, last Wednesday unless otherwise stated, Bank of Canada, monthly
 Bank_rate_ARIMA.st <- get_cansim_vector( Bank_rate_ARIMA_raw, start_time = "2008/01/01", end_time = "2022/12/31")
 Bank_rate_ARIMA_year.st <- year( Bank_rate_ARIMA.st$REF_DATE[1])
 Bank_rate_ARIMA_month.st <- month( Bank_rate_ARIMA.st$REF_DATE[1])
c( Bank_rate_ARIMA_year.st,  Bank_rate_ARIMA_month.st)

 Bank_rate_ARIMA.ts<- ts( Bank_rate_ARIMA.st$VALUE, start = c( Bank_rate_ARIMA_year.st,  Bank_rate_ARIMA_month.st), freq = 12)
################

```



The conditional forecasting 2: The CPI with the bank rate
```{r}

#we are assuming we are in no late 2023/1/17  
#Consumer Price Index (CPI)
CPI_ARIMA.raw <- "v41690914" #Consumer Price Index, monthly, seasonally adjusted, monthly (2002=100) 
CPI_ARIMA.st <- get_cansim_vector(CPI_ARIMA.raw, start_time = "2007/01/01", end_time = "2022/12/31")
CPI_ARIMA_year.st <- year(CPI_ARIMA.st$REF_DATE[1])
CPI_ARIMA_month.st <- month(CPI_ARIMA.st$REF_DATE[1])
#transfer data to the time series time
c(CPI_ARIMA_year.st, CPI_ARIMA_month.st)
CPI_ARIMA.ts<- ts(CPI_ARIMA.st$VALUE, start = c(CPI_ARIMA_year.st, CPI_ARIMA_month.st), freq = 12)
#now its time series data!
#plot(CPI.ts)
####
```



```{r}
Can_month_housing_sell_ARIMA.ts <- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2022, 12), frequency = 12)

###### station CPI and housing resale#
#stationary_CPI_ARIMA.ts <- (100 * diff(log(CPI_ARIMA.ts), lag = 12))
Stationary_housing_resale_ARIMA.ts <- 100* diff(log(Can_month_housing_sell_ARIMA.ts), lag = 12)
#adf.test(Stationary_housing_resale_ARIMA.ts)
Housing_sell_Stationary_CPI.ts <- cbind(Stationary_housing_resale_ARIMA.ts, Bank_rate_ARIMA.ts)
```



Try the lag test
```{r}
# The_lage_test
BankRate <- cbind(
  BankRateLag0 = Housing_sell_Stationary_CPI.ts[,"Bank_rate_ARIMA.ts"],
  BankRateLag1 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Bank_rate_ARIMA.ts"], 1),
  BankRateLag2 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Bank_rate_ARIMA.ts"], 2),
  BankRateLag3 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Bank_rate_ARIMA.ts"], 3),
  BankRateLag4 = stats::lag(Housing_sell_Stationary_CPI.ts[,"Bank_rate_ARIMA.ts"], 4)
) %>% head(NROW(Housing_sell_Stationary_CPI.ts))

# Fit ARIMA models
fit1 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1], stationary=TRUE)
fit2 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1:2], stationary=TRUE)
fit3 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1:3], stationary=TRUE)
fit4 <- auto.arima(Housing_sell_Stationary_CPI.ts[4:40, 1], xreg=BankRate[4:40, 1:4], stationary=TRUE)

# Show AICc values
cat("AICc values:", fit1[["aicc"]], fit2[["aicc"]], fit3[["aicc"]], fit4[["aicc"]], "\n")

#only lag one? 
```




now is generate the dynamatic regression's acutally arima model.
```{r}

The_conditional_forecasting_2 <- auto.arima(Stationary_housing_resale_ARIMA.ts, xreg = Bank_rate_ARIMA.ts,  approximation = FALSE, parallel = TRUE, stepwise = FALSE, num.cores = 10)

```


What if the policy rate remain 4.5 for next 12 month
```{R}

Stationary_Bank_ARIMA_forecasting_1.ts <- matrix(rep(4.5, times = 12), ncol = 1)


autoplot(forecast(The_conditional_forecasting_2, 
                 h = 12, 
                 xreg = Stationary_Bank_ARIMA_forecasting_1.ts)) +
  theme_fivethirtyeight() +
  xlab("Year") +
  ylab("Percentage") +
  ggtitle("Forecasting of Canadian Housing Resales") +
  labs(subtitle = "If the policy rate stay at 4.5% current level for 12 months") +
  theme(axis.title = element_text())

#it not working very good?
#but why?
```

What if the policy rate remain 1.75 for next 12 month (the average in 2019)

```{r}
Stationary_Bank_ARIMA_forecasting_2.ts <- matrix(rep(1.75, times = 12), ncol = 1)


autoplot(forecast(The_conditional_forecasting_2, 
                 h = 12, 
                 xreg = Stationary_Bank_ARIMA_forecasting_2.ts)) +
  theme_fivethirtyeight() +
  xlab("Year") +
  ylab("Percentage") +
  ggtitle("Forecasting of Canadian Housing Resales") +
  labs(subtitle = "If the policy rate stay at 4.5% current level for 12 months") +
  theme(axis.title = element_text())

#it not working very good?
#but why?

```





Part 2 VAR model 

For better understand and forecasting the reltionahup between the canadian housing relase and other macro economic data relative to the business cycle. I contrucede model include the bank rate, gdp and infaltion and unmpleotymenr rate



First: data collection
```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
Evil.begain <- "2007/01/01"
Evil.end <- "2022/12/31"


#The GDP data Canada [11124]; Seasonally adjusted at annual rates; 2012 constant prices; All industries
CA_GDP_raw <- "v65201483"
CA_GDP.st <- get_cansim_vector(CA_GDP_raw, start_time =  "2007/01/01", end_time = "2022/12/31")
CA_GDP_year.st <- year(CA_GDP.st$REF_DATE[1])
CA_GDP_month.st <- month(CA_GDP.st$REF_DATE[1])
#transfer data to the time series time
c(CA_GDP_year.st, CA_GDP_month.st)
CA_GDP.ts <-ts(CA_GDP.st$VALUE, start = c(CA_GDP_year.st, CA_GDP_month.st), freq = 12)
plot(CA_GDP.ts)
#autoplot(CA_GDP.ts)

#get the data form statistic Canada
unemployment_rate_raw <- "v2062815" #Unemployment rate (Percentage); Both sexes; 15 years and over; Estimate; SA, Monthly.
unemployment.st <- get_cansim_vector(unemployment_rate_raw, start_time = "2008/01/01", end_time = "2022/12/31")
unemployment_rate_year.st <- year(unemployment.st$REF_DATE[1])
unemployment_rate_month.st <- month(unemployment.st$REF_DATE[1])
#transfer data to the time series time
c(unemployment_rate_year.st, unemployment_rate_month.st)
unemployment_rate.ts<- ts(unemployment.st$VALUE, start = c(unemployment_rate_year.st, unemployment_rate_month.st), freq = 12)
#now its time series data!
#plot(unemployment_rate.ts)

#we are assuming we are in no late 2023/1/17 
#Consumer Price Index (CPI)
CPI_raw <- "v41690914" #Consumer Price Index, monthly, seasonally adjusted, monthly (2002=100) 
CPI.st <- get_cansim_vector(CPI_raw, start_time = "2007/01/01", end_time = "2022/12/31")
CPI_year.st <- year(CPI.st$REF_DATE[1])
CPI_month.st <- month(CPI.st$REF_DATE[1])
#transfer data to the time series time
c(CPI_year.st, CPI_month.st)
CPI.ts<- ts(CPI.st$VALUE, start = c(CPI_year.st, CPI_month.st), freq = 12)
#now its time series data!
#plot(CPI.ts)

####
#The bank rate 
Bank_rate_raw <- "v122530" #Financial market statistics, last Wednesday unless otherwise stated, Bank of Canada, monthly 
Bank_rate.st <- get_cansim_vector(Bank_rate_raw, start_time = "2008/01/01", end_time = "2022/12/31")
Bank_rate_year.st <- year(Bank_rate.st$REF_DATE[1])
Bank_rate_month.st <- month(Bank_rate.st$REF_DATE[1])

#transfer data to the time series time
c(Bank_rate_year.st, Bank_rate_month.st)
Bank_rate.ts<- ts(Bank_rate.st$VALUE, start = c(Bank_rate_year.st, Bank_rate_month.st), freq = 12)
#now its time series data!
#plot(Bank_rate.ts)

Can_month_housing_sell_var<- ts(Can_housing_sell_data.raw$Canada, start = c(2007, 1), end = c(2022, 12), frequency = 12)

####

#we are assuming we are in no late 2023/1/17 
#New housing price index, monthly, monthly (Index, 201612=100) 
New_housing_price_index_raw <- "v111955442" 
New_housing_price_index.st <- get_cansim_vector(New_housing_price_index_raw, start_time = "2006/01/01", end_time = Evil.end)
New_housing_price_index_year.st <- year(New_housing_price_index.st$REF_DATE[1])
New_housing_price_index_month.st <- month(New_housing_price_index.st$REF_DATE[1])
#transfer data to the time series time
c(New_housing_price_index_year.st, New_housing_price_index_month.st)
New_housing_price_index.ts<- ts(New_housing_price_index.st$VALUE, start = c(New_housing_price_index_year.st, New_housing_price_index_month.st), freq = 12)
#now its time series data!
#autoplot()
New_housing_price_index_VAR.raw <- 100* diff(log(New_housing_price_index.ts), lag = 12)
new_housing_price_index_VAR.ts <- window(New_housing_price_index_VAR.raw, start= c(2008,1), end= c(2022,12))

###

 Prime_rate_raw <- "V80691311" #Financial market statistics, last Wednesday unless otherwise stated, Bank of Canada, monthly
 Prime_rate.st <- get_cansim_vector(Prime_rate_raw, start_time = "2008/01/01", end_time = "2022/12/01")
 print(Prime_rate.st)
 
 
 Prime_rate_year.st <- year( Prime_rate.st$REF_DATE[1])
 Prime_rate_month.st <- month( Prime_rate.st$REF_DATE[1])
  c(Prime_rate_year.st,  Prime_rate_month.st)
  
  Prime_rate.ts<- ts(Prime_rate.st$VALUE, start = c( Prime_rate_year.st, Prime_rate_month.st), freq = 52)

prime_rate_monthly <- ts(aggregate(Prime_rate.ts, nfrequency = 52/12, FUN = mean), start = c(2008, 1), end = c(2022, 12), frequency = 12)
prime_rate_monthly_full.ts<- na.interp(prime_rate_monthly)


#### The housing price index

The_housing_price<- read_excel("/Users/tie/Documents/GitHub/ECON-493-forcasting-economy/The research project/News_release_chart_data_mar_2023.xlsx", 
    sheet = "Chart 4", col_types = c("date", "skip",  "numeric", "numeric", "text"))


The_housing_price_raw.ts <- ts(The_housing_price$`MLS® HPI Aggregate Composite Benchmark†`, start = c(2005, 1), end = c(2023, 2), frequency = 12)

#I really need to learn how to cut the size of my variable name lol
The_housing_price_VAR_stationary.raw <-100* diff(log(The_housing_price_raw.ts), lag = 12)

#pass the stationary check
#adf.test(The_housing_price_VAR_stationary)
#0.01565 pass the stationary 
#cut to the suitable size
The_housing_price_VAR_stationary.ts <- window(The_housing_price_VAR_stationary.raw, start= c(2008,1), end= c(2022,12))

```


```{r}

#Variable Transformation########################################

  #5.2.1 stationary CA_GDP.ts 
stationary_CA_GDP.ts <- 100 *diff(log(CA_GDP.ts), lag = 12)
  #5.2.2 leacve unemployment rate as it is 
      #unemployment_rate.ts
  #5.2.3 stationary CPI.ts
  Stationary_CPI.ts<- 100 * diff(log(CPI.ts), lag = 12)
  #5.2.4 leave bank rate as it is
  #5.2.5 stationary the housing sell 
stationary_Can_month_housing_sell.ts <- 100*diff(log(Can_month_housing_sell_var.ts), lag = 12)

#5.2.5 put all data together
all_data <- cbind(stationary_Can_month_housing_sell.ts,stationary_CA_GDP.ts, Stationary_CPI.ts, prime_rate_monthly_full.ts, The_housing_price_VAR_stationary.ts, new_housing_price_index_VAR.ts, Bank_rate.ts, unemployment_rate.ts)

```


doing the best subselection
why? because var model crashed....
```{r message=FALSE, warning=FALSE, paged.print=FALSE}

library(leaps)

#best subset selection
#transfer data into the df
all_data_df <- data.frame(all_data)

all_dat_fun <-cbind(SGDP = stationary_CA_GDP.ts, SCPI = Stationary_CPI.ts, PR = prime_rate_monthly_full.ts, HP = The_housing_price_VAR_stationary.ts, BK = Bank_rate.ts, NPH = new_housing_price_index_VAR.ts, UR = unemployment_rate.ts)


####

# plot results
par(mfrow=c(1,3))
plot(reg.summary$rss, xlab = "Number of Variables", ylab = "SSR", type = "l")
plot(reg.summary$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
m.bic <- which.min(reg.summary$bic)
points(m.bic, reg.summary$bic[m.bic], col = "green", cex = 2, pch = 20)
plot(reg.summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
m.cp <- which.min(reg.summary$cp)
points(m.cp, reg.summary$cp[m.cp], col = "yellow", cex = 2, pch = 20)
layout(1)

#the best varialbe. = 5 


#####

 data2 <- data.frame(all_dat_fun, stationary_Can_month_housing_sell.ts)

regfit.all <- regsubsets(stationary_Can_month_housing_sell.ts ~. , data = data2, nvmax = 100, really.big = TRUE, method = "exhaustive")



reg.summary <- summary(regfit.all)

plot(regfit.all, scale = "bic")



```

The idea variable are 5
SGPD, SCPI, HP, NPH, UR




```{r}

#the Var data
Var_all_data <- cbind(stationary_Can_month_housing_sell.ts, stationary_CA_GDP.ts, Stationary_CPI.ts, The_housing_price_VAR_stationary.ts, new_housing_price_index_VAR.ts, unemployment_rate.ts)

#check if the data has similar trend
#autoplot(Var_all_data, facets = T)
  #not really? 


#need to do something relative to the causality here? 
#the unemployment rate going because it did not pass the granger causality test

#the actally var data 
Var_all_data <-cbind(stationary_Can_month_housing_sell.ts, SGDP = stationary_CA_GDP.ts, SCPI = Stationary_CPI.ts, HP = The_housing_price_VAR_stationary.ts,  NPH = new_housing_price_index_VAR.ts)

#The covid dummy variable
The_covid_dummy_VAR.ts <- ts(The_covid_dummy$Covid_dummy, start = c(2008, 1), end = c(2022, 12), frequency = 12)
 
#put bank rate with covid dummy variable together.
exogen_variable <- cbind(The_covid_dummy_VAR.ts, Bank_rate.ts)

#we can see how the bank rate and covid dummy variable impact on the entire housing resale market.


VARselect(Var_all_data, exogen = exogen_variable,  type="const", lag.max = 11)
#according to the instructor, using BIC! 
#lag 2!!!!!!!


#At here I was planning to do the cross validation for 4 different model, then I gived up.
two_exogen_Var_model <- VAR(Var_all_data,  exogen = exogen_variable, p = 2, type="const")

Bankrate_Var_model <- VAR(Var_all_data,  exogen = Bank_rate.ts, p = 2, type="const")

Covid_var_model <-  VAR(Var_all_data,  exogen = The_covid_dummy_VAR.ts, p = 2, type="const")
  
var_model <- VAR(Var_all_data, p = 2, type="const")





```



```{R echo=FALSE, message=FALSE, warning=FALSE}
# 5.3 Granger Causality Tests

# Run Granger causality tests
housing_gdp_causality <- causality(The_evil_model, cause = "SGDP")$Granger
housing_CPI_causality <- causality(The_evil_model, cause = "SCPI")$Granger
housing_houing_price_causality <- causality(The_evil_model, cause = "HP")$Granger
housing_new_houing_price_causality <- causality(The_evil_model, cause = "NPH")$Granger
housing_new_houing_price_causality <- causality(The_evil_model, cause = "cobi")$Granger
housing_prime_rate_causality <- causality(The_evil_model, cause = "The_covid_dummy_VAR.ts")$Granger


#put here so I can copy and past it...
#Var_all_data <-cbind(stationary_Can_month_housing_sell.ts, SGDP = stationary_CA_GDP.ts, SCPI = Stationary_CPI.ts, HP = The_housing_price_VAR_stationary.ts,  NPH = new_housing_price_index_VAR.ts, UR = unemployment_rate.ts)



# Print the results

print(housing_gdp_causality)
print(housing_CPI_causality)
print(housing_houing_price_causality)
print(housing_new_houing_price_causality)
print(housing_prime_rate_causality)

#missing the var without exgon...
#now need to do the function first...
#autoplot(forecast(The_evil_model, h = 12))

```
interrdting enroughh that the unemploymetn rate has vey litter granfger causality test with the rest of data. 





