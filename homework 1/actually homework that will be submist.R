#################################################################################################################
#Tie Ma
#student number: 1537905
#this code need to be cleaned up....
#################################################################################################################

#Clean the enviroment
#rm(list = ls())
#dev.off()

#set the direction
setwd("~/SynologyDrive/nn/ECON-493-forcasting-economy/homework 1")

#create a new file for all the generated by the graphic content
dir.create("pics")

#Lode the all package that necessary.
install.packages("r2symbols")
install.packages("ggplot2")
install.packages("fpp2")
install.packages("glmnet")
install.packages("tidyr")
install.packages("lmtest")
#library("r2symbols") #各种奇形怪状的符号
library("ggplot2")
library("fpp2")
library("glmnet")
library("mosaicCalc")#微积分计算器！
library("tidyr")
library("lmtest")
library("boot")


#doctor who blue 
DW = "#003b6f"
  ##################################################################################################

# Exercise two
# regression y= βx + u 
# n = 1, y1 = 2， x1 = 1

#2-1 plot (2-b)^2 

eq = function(b){(2-b)^2}
#set the equation
x <- seq(-100,100, by=0.01)
#give the x a group of number from -100 to 100
y <- eq(x)
#y is equal to the number of that processed by the function
df <- data.frame(x,y)
#make it as data frame
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
#
#faster way
#eq = function(b){(2-b)^2}
#curve(eq, -10,10)

##saving the graph
pdf("pics/TieMa_homework1_Q2_1.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()

#2-c
eq = function(b){b^2}
x <- seq(-100,100, by=0.01)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q2_2.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()

rm(list = ls()) 


#2-d 
#plot the graphy of (2-b)^2 + b^2


eq = function(b){(2-b)^2 + b^2}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 

##saving the graph
pdf("pics/TieMa_homework1_Q2_3.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()


# 2-e
#trying using R to do the calculise
install.packages("mosaicCalc")
library(mosaicCalc)
#credit: https://cran.r-project.org/web/packages/mosaicCalc/vignettes/Calculus_with_R.html

#D(a / x ~ x) #dx/db(a/x)
#D(x^2 ~ x)
#function (x) 
#2 * x

D((((6-b)^2) + b^2) ~ b)

#the function
#function (b) 
# 4 * (b - 1)

# let 4 * (b - 1) = 0 to find the beta hat ridge
# 4b - 4 = 0

uniroot.all(function(x,a,b) a*x+b,a=4,b=4,lower=-10,upper=10,tol=0.0001)
#find al the root

#2.e
#the answer is -1


################################################################################################################################
#2 -f 
#let the lambda ridge = 0.5 re do the question c and d

#plot the function 0.5 * b^2

eq = function(b){0.5*b^2}
x <- seq(-5,5, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 

##saving the graph
pdf("pics/TieMa_homework1_Q2_f.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()

#find the value of lambda beta hat

D(0.5 * b^2 ~ b)

#the function
#function (b) 
# b

# let  b = 0 to find the beta hat ridge

# lambda beta hat = 0

################################################################################################################################

#2-f-2-1 repeat the (d) and find the value of lambda beta hat

eq = function(b){0.5 * b^2}
x <- seq(-5,5, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 

##saving the graph
pdf("pics/TieMa_homework1_Q2_f_2.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()



#############################################################################################################################################
#2-f-2-1 lambda ridge = 0.5 and redue the question d

#first, let's plot the graphy

#(2-b)^2 + 0.5*b^2

eq = function(b){(2-b)^2 + 0.5*b^2}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q2_f_repeat_question_d_plot_the graphy.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()

#find the value of lambda beta hat

D((2-x)^2 + (0.5*x^2) ~x)
#function (x) 
#3 * x - 4

#let 3x-4=0, then we can get the lambda beta hat is 4/3

#############################################################################################################################################     







#############################################################################################################################################     
#exercise 3
############################################################################################################################################# 

#3-a

eq = function(b){(2-b)^2}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_a.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()



############################################################################################################################################# 


#3-c

eq = function(b){abs(b)}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_C.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()

############################################################################################################################################# 

#3-d

eq = function(b){(2-b)^2 + abs(b)}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_d.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()

############################################################################################################################################# 

#3-e

D((2-b)^2 + abs(b) ~ b)

#function (b) 
#sign(b) + 2 * b - 4
#not enough math knowledge deal in r, i will go for handwriting

############################################################################################################################################# 

#3-f-1 labamta = 0.5 repeat c and d

#c
eq = function(b){0.5*abs(b)}
x <- seq(-5,5, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_f_1.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()


#d
eq = function(b){(2-b)^2 + 0.5*abs(b)}
x <- seq(-5,5, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_f_2.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()

############################################################################################################
#Q3-g labamta = 4 repeat c and d


#c
eq = function(b){4 * abs(b)}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_g_1.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()


#d
eq = function(b){(2-b)^2 + 4*abs(b)}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_g_2.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()

#################################################################################################################



#################################################################################################################
#Exercise 4 

#generate the simulated data
#################################################################################################################
set.seed(1234)
n.obs <- 100
x1 <- rnorm(n.obs)
y <- x1 - 2*x1^2 + rnorm(n.obs)
#################################################################################################################
#4-b
df <-data.frame(x1,y)
plot(df, main="Question 4-B", 
     xlab="x1 ", ylab="y1 ", pch=1,col='#003b6f')


#save the graphy
pdf("pics/TieMa_homework1_Q4_B.pdf", height = 9, width = 12)
plot(df, main="Question 4-B", 
     xlab="x1 ", ylab="y1 ", pch=1,col='#003b6f')

#clean the enviroment!
rm(list = ls())
#4-b-2
#From the graphy we could find nonlinear relationship between x1 and y
#################################################################################################################
#Q4-c

######################################################
#generate the simulated data (again, in order to avoid this section been polluted)
set.seed(1234)
n.obs <- 100
x1 <- rnorm(n.obs)
x2 <- x1^2
x3 <- x1^3
x4 <- x1^4
y <- x1 - 2*x1^2 + rnorm(n.obs)
Q4_data_set <- data.frame(y, x1, x2, x3, x4)
######################################################
#beta one? 

model_one <- lm(y ~ x1, data=Q4_data_set)
##########

model_two <- lm(y ~ x1+x2, data=Q4_data_set)
#########

model_three <- lm(y ~ x1+x2+x3, data=Q4_data_set)
##########

model_four <- lm(y ~ x1+x2+x3+x4, data=Q4_data_set)

evil <- rbind(CV(model_one), CV(model_two), CV(model_three), CV(model_four))
rownames(evil) <- c('Model1', 'Model2', 'Model3', 'Model4')
evil

#.          CV       AIC      AICc       BIC       AdjR2
#Model1 9.217431 218.96020 219.21020 226.77571 0.009513121
#Model2 1.094918  11.79099  12.21204  22.21167 0.876435778
#Model3 1.101478  13.45234  14.09064  26.47819 0.875570749
#Model4 1.115254  15.42932  16.33255  31.06034 0.874289903


#by compare AIC and BIC we can concluded following
#model 2 > model 3 > model4 > model 1
#the smaller the betterm therefore, the model 2 have lowest AIC and BIC, it is relative better model to use 

#################################################################################################################
# Q4-V Compute the k-fold cross-validation errors that result from fitting the four models. Use
#k = 5. Which model would you prefer? Is this what you expected? Explain your answer.


#################################################################################################################################
#clean the enviroment and generate everything again....
rm(list = ls())

#create the chart that carry the number od the cross-vaidation error
cv.error <- rep(NA,4)

#simulate data and enviorment.

set.seed(1234)
n.obs <- 100
x1 <- rnorm(n.obs)
x2 <- x1^2
x3 <- x1^3
x4 <- x1^4
y <- x1 - 2*x1^2 + rnorm(n.obs)
Q4_data_set_2 <- data.frame(y, x1, x2, x3, x4)

head(Q4_data_set_2, 2) #check it!!


model_one_with_data_set.cv <- glm(y ~ x1)
cv.error[1] <-cv.glm(Q4_data_set_2, model_one_with_data_set.cv, K=5)$delta[1]
print(cv.error)


#################################################################################################################################
#model 2 data set


model_two_with_data_set.cv <- glm(y ~ x1 + x2)
cv.error[2] <-cv.glm(Q4_data_set_2, model_two_with_data_set.cv, K=5)$delta[1]
print(cv.error)


#################################################################################################################################
#model 3


model_three_with_data_set.cv <- glm(y ~ x1 + x2 + x3)
cv.error[3] <-cv.glm(Q4_data_set_2, model_three_with_data_set.cv, K=5)$delta[1]
print(cv.error)

##################################################################################################################################
#model 4


model_four_with_data_set.cv <- glm(y ~ x1 + x2 +x3 +x4)
cv.error[4] <-cv.glm(Q4_data_set_2, model_four_with_data_set.cv, K=5)$delta[1]
print(cv.error)

#I spend 3 hours on those code, god its finally down.....
##################################################################################################################################

# The 5- fold corss-validation errors
#8.865048 1.078610 1.157496 1.115773

#low fold cross validation erros may relate to the problem of over fitting, 
#the AIC and BIC test are working on find the model that fit the data better with relative smllar variance
# It show the similar perference as the result with. the AIC and BIC test. 

##################################################################################################################################

#clean the enviroment!
rm(list = ls())

##################################################################################################################################
#Exercise 5 
##################################################################################################################################
#Exercise 5-a
#Create a matrix X (545 × 9) with the 7 explanatory variables described above plus experience and schooling squared. 
#Scale the matrix X such that all variables have the same variance. Create a vector y (545 × 1) with log wage.
install.packages("leaps")
library("leaps")

#lode the data
X_df <-read.csv("data/males1987.csv", header = TRUE)

#check the data!
class(X_df)
str(X_df)
head(X_df, 4)

#move the logwage in the first col
X_relocated <- relocate(X_df, LOGWAGE, before = )
#AFTER SPEND 3 HOURS FINALLY DOWN

#check the data!
str(X_relocated)
head(X_relocated, 4)
#It look good


#now square experience and school

X_relocated_final<- X_relocated %>% select(LOGWAGE, BLACK, EXPER, HISP, MAR, SCHOOL, UNION, EXPER2) %>% mutate(SCHOOL2 = SCHOOL^2)

#check the data
head(X_relocated_final, 4)
#its look good!

X_Scale <- X_relocated_final%>% select(LOGWAGE, BLACK, EXPER, HISP, MAR, SCHOOL, UNION, SCHOOL2, EXPER2)  %>% transmute(LOGWAGE_scale =scale(LOGWAGE) , BLACK, EXPER_scale = scale(EXPER), HISP, MAR, SCHOOL_scale = scale(SCHOOL), UNION, EXPER2_scale = scale(EXPER2), SCHOOL2_scale = scale(SCHOOL2))
#sorry for this line of code is way too long...
#I did not really sure how to shrink it down...
#It select the all the variable 
#and using the scale function to scale the non-dummy variable...


#check the data!
head(X_Scale, 4)
#it look good!

#check what the data is
class(X_Scale)
# its data frame! 

#transfer to matrix
X <- data.matrix(X_Scale)

#check if the data actually been scale()
summary(X_Scale)
var.all <- rep(NA,5)
var.all[1] <- var(X_Scale$LOGWAGE_scale)
var.all[2]<- var(X_Scale$EXPER_scale)
var.all[3]<- var(X_Scale$SCHOOL_scale)
var.all[4]<- var(X_Scale$EXPER2_scale)
var.all[5]<- var(X_Scale$SCHOOL2_scale)
print(var.all)

#[1] 1 1 1 1 1
var(X_Scale$SCHOOL2_scale)
#all non dummy variable have the same variance 

#Create a vector y with log wage
#recall we have the matrix X that include all the data

x<- X_Scale%>%
  dplyr::select(
    BLACK, EXPER_scale, HISP, MAR, SCHOOL_scale, UNION, EXPER2_scale,
    SCHOOL2_scale
  )%>%
  data.matrix()

#check the data!
head(X_final_version)

##################################################################################################################################

#Q5-b
y_THE_LOGWAGE <- X_Scale$LOGWAGE_scale
data_question5 <- data.frame(x,y_THE_LOGWAGE)


# ridge regression for different values of lambda
evil_grid <- 10^seq(3, -3, length = 100)
ridge.mod <- glmnet(x, y_THE_LOGWAGE, alpha = 0, lambda = grid)

#plot ridge results
plot(ridge.mod, xvar = "lambda", label = TRUE)


##################################################################################################################################
#Q5-C

# cr
paerameters_Q5 <- matrix(rep(NA),12,2)

table1[,1] <- coef1
table1[c(1:6),2] <- coef2
table1[,3] <- coef3[,1]
table1 <- data.frame(table1)
colnames(table1) <- c("ols", "bss", "lasso")
rownames(table1) <- rownames(coef3)
table1






