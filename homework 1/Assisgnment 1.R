#################################################################################################################
#Tie Ma
#student number: 1537905
#this code need to be cleaned up....
#################################################################################################################

#Clean the enviroment
#rm(list = ls())
#dev.off()

#set the direction
setwd("~/SynologyDrive/nn/ECON-493-forcasting-economy/homework 1")

#create a new file for all the generated by the graphic content
dir.create("pics")

#Lode the all package that necessary.
install.packages("r2symbols")
install.packages("ggplot2")
install.packages("fpp2")
install.packages("glmnet")
install.packages("tidyr")
install.packages("lmtest")
#library("r2symbols") #各种奇形怪状的符号
library("ggplot2")
library("fpp2")
library("glmnet")
library("mosaicCalc")#微积分计算器！
library("tidyr")
library("lmtest")
library("boot")

#doctor who blue 
DW = "#003b6f"
##################################################################################################

# Exercise two
# regression y= βx + u 
  # n = 1, y1 = 2， x1 = 1

#2-1 plot (2-b)^2 
  
  eq = function(b){(2-b)^2}
  #set the equation
  x <- seq(-100,100, by=0.01)
  #give the x a group of number from -100 to 100
  y <- eq(x)
  #y is equal to the number of that processed by the function
  df <- data.frame(x,y)
  #make it as data frame
  ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
  #
  #faster way
  #eq = function(b){(2-b)^2}
  #curve(eq, -10,10)
  
  ##saving the graph
  pdf("pics/TieMa_homework1_Q2_1.pdf", height = 9, width = 12)
  ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
  dev.off()
  
 #2-c
  eq = function(b){b^2}
  x <- seq(-100,100, by=0.01)
  y <- eq(x)
  df <- data.frame(x,y)
  ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 

  
  ##saving the graph
  pdf("pics/TieMa_homework1_Q2_2.pdf", height = 9, width = 12)
  ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
  dev.off()
 
  rm(list = ls()) 
 
   
#2-d 
  #plot the graphy of (2-b)^2 + b^2
  
  
  eq = function(b){(2-b)^2 + b^2}
  x <- seq(-10,10, by=0.001)
  y <- eq(x)
  df <- data.frame(x,y)
  ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
  
  ##saving the graph
  pdf("pics/TieMa_homework1_Q2_3.pdf", height = 9, width = 12)
  ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
  dev.off()
  
  
# 2-e
  #trying using R to do the calculise
  install.packages("mosaicCalc")
  library(mosaicCalc)
  #credit: https://cran.r-project.org/web/packages/mosaicCalc/vignettes/Calculus_with_R.html

 #D(a / x ~ x) #dx/db(a/x)
 #D(x^2 ~ x)
 #function (x) 
  #2 * x

D((((6-b)^2) + b^2) ~ b)

    #the function
    #function (b) 
    # 4 * (b - 1)

# let 4 * (b - 1) = 0 to find the beta hat ridge
# 4b - 4 = 0

uniroot.all(function(x,a,b) a*x+b,a=4,b=4,lower=-10,upper=10,tol=0.0001)
#find al the root

#2.e
  #the answer is -1


################################################################################################################################
#2 -f 
  #let the lambda ridge = 0.5 re do the question c and d

  #plot the function 0.5 * b^2
  
eq = function(b){0.5*b^2}
x <- seq(-5,5, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 

##saving the graph
pdf("pics/TieMa_homework1_Q2_f.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()
  
  #find the value of lambda beta hat
    
         D(0.5 * b^2 ~ b)

#the function
#function (b) 
# b

# let  b = 0 to find the beta hat ridge

# lambda beta hat = 0
         
################################################################################################################################
         
#2-f-2-1 repeat the (d) and find the value of lambda beta hat
         
eq = function(b){0.5 * b^2}
x <- seq(-5,5, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
         
 ##saving the graph
pdf("pics/TieMa_homework1_Q2_f_2.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()
         
         
             
#############################################################################################################################################
#2-f-2-1 lambda ridge = 0.5 and redue the question d

#first, let's plot the graphy

#(2-b)^2 + 0.5*b^2

eq = function(b){(2-b)^2 + 0.5*b^2}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q2_f_repeat_question_d_plot_the graphy.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()
         
#find the value of lambda beta hat

D((2-x)^2 + (0.5*x^2) ~x)
#function (x) 
#3 * x - 4

#let 3x-4=0, then we can get the lambda beta hat is 4/3

#############################################################################################################################################     







#############################################################################################################################################     
#exercise 3
############################################################################################################################################# 

#3-a

eq = function(b){(2-b)^2}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_a.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()



############################################################################################################################################# 


#3-c

eq = function(b){abs(b)}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_C.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()

############################################################################################################################################# 

#3-d

eq = function(b){(2-b)^2 + abs(b)}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_d.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()

############################################################################################################################################# 

#3-e

D((2-b)^2 + abs(b) ~ b)

#function (b) 
#sign(b) + 2 * b - 4
#not enough math knowledge deal in r, i will go for handwriting

############################################################################################################################################# 

#3-f-1 labamta = 0.5 repeat c and d

  #c
eq = function(b){0.5*abs(b)}
x <- seq(-5,5, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_f_1.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()


  #d
eq = function(b){(2-b)^2 + 0.5*abs(b)}
x <- seq(-5,5, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_f_2.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()

############################################################################################################
#Q3-g labamta = 4 repeat c and d


#c
eq = function(b){4 * abs(b)}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_g_1.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()


#d
eq = function(b){(2-b)^2 + 4*abs(b)}
x <- seq(-10,10, by=0.001)
y <- eq(x)
df <- data.frame(x,y)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 


##saving the graph
pdf("pics/TieMa_homework1_Q3_g_2.pdf", height = 9, width = 12)
ggplot(df, aes(x=x, y=y)) + geom_line(col='#003b6f')  + geom_hline(yintercept = 0)+geom_vline(xintercept = 0) + stat_function(fun = eq) 
dev.off()

#################################################################################################################



#################################################################################################################
#Exercise 4 

#generate the simulated data
#################################################################################################################
set.seed(1234)
n.obs <- 100
x1 <- rnorm(n.obs)
y <- x1 - 2*x1^2 + rnorm(n.obs)
#################################################################################################################
#4-b
df <-data.frame(x1,y)
plot(df, main="Question 4-B", 
     xlab="x1 ", ylab="y1 ", pch=1,col='#003b6f')


#save the graphy
pdf("pics/TieMa_homework1_Q4_B.pdf", height = 9, width = 12)
plot(df, main="Question 4-B", 
     xlab="x1 ", ylab="y1 ", pch=1,col='#003b6f')

#clean the enviroment!
rm(list = ls())
#4-b-2
  #From the graphy we could find nonlinear relationship between x1 and y
#################################################################################################################
#Q4-c

######################################################
#generate the simulated data (again, in order to avoid this section been polluted)
set.seed(1234)
n.obs <- 100
x1 <- rnorm(n.obs)
x2 <- x1^2
x3 <- x1^3
x4 <- x1^4
y <- x1 - 2*x1^2 + rnorm(n.obs)
Q4_data_set <- data.frame(x1,y)
######################################################
#beta one? 

model_one <- lm(y ~ x1, data=Q4_data_set)

##########

model_two <- lm(y ~ x1+x2, data=Q4_data_set)

#########

model_three <- lm(y ~ x1+x2+x3, data=Q4_data_set)

##########

model_four <- lm(y ~ x1+x2+x3+x4, data=Q4_data_set)

evil <- rbind(CV(model_one), CV(model_two), CV(model_three), CV(model_four))
rownames(evil) <- c('Model1', 'Model2', 'Model3', 'Model4')
evil

#.          CV       AIC      AICc       BIC       AdjR2
#Model1 9.217431 218.96020 219.21020 226.77571 0.009513121
#Model2 1.094918  11.79099  12.21204  22.21167 0.876435778
#Model3 1.101478  13.45234  14.09064  26.47819 0.875570749
#Model4 1.115254  15.42932  16.33255  31.06034 0.874289903


#by compare AIC and BIC we can concluded following
#Model1 <Model2 <Model3 <Model4
#the smaller the better

#################################################################################################################
# Q4-V Compute the k-fold cross-validation errors that result from fitting the four models. Use
#k = 5. Which model would you prefer? Is this what you expected? Explain your answer.


#################################################################################################################################
#model 1 data set

cv.error <- rep(NA,4)
set.seed(1234)
n.obs <- 100
e <- rnorm(n.obs)
x1 <- rnorm(n.obs)

y <- x1 + e
model_one_data_set <- data.frame(y,x1)
head(model_one_data_set, 2) #check it!!


model_one_with_data_set.cv <- glm(y ~ x1)
cv.error[1] <-cv.glm(model_one_data_set, model_one_with_data_set.cv, K=5)$delta[1]
print(cv.error)


#################################################################################################################################
#model 2 data set

set.seed(1234)
n.obs <- 100
e <- rnorm(n.obs)
x1 <- rnorm(n.obs)
x2 <- x1^2
y <- x1 + x1^2 + e

model_two_data_set <- data.frame(y,x1,x2)
head(model_two_data_set, 2) #check it!!

model_two_with_data_set.cv <- glm(y ~ x1 + x2)
cv.error[2] <-cv.glm(model_two_data_set, model_two_with_data_set.cv, K=5)$delta[1]
print(cv.error)


#################################################################################################################################
#model 3

set.seed(1234)
n.obs <- 100
e <- rnorm(n.obs)
x1 <- rnorm(n.obs)
x2 <- x1^2
x3 <- x1^3

y <- x1 + x1^2 + x1^3 + e

model_three_data_set <- data.frame(y,x1,x2,x3)
head(model_three_data_set, 2) #check it!!

model_three_with_data_set.cv <- glm(y ~ x1 + x2 + x3)
cv.error[3] <-cv.glm(model_three_data_set, model_three_with_data_set.cv, K=5)$delta[1]
print(cv.error)

##################################################################################################################################
#model 4

set.seed(1234)
n.obs <- 100
e <- rnorm(n.obs)
x1 <- rnorm(n.obs)
x2 <- x1^2
x3 <- x1^3
x4 <- x1^4

y <- x1 + x1^2 + x1^3 + x1^4 + e

model_four_data_set <- data.frame(y,x1,x2,x3,x4)
head(model_four_data_set, 2) #check it!!

model_four_with_data_set.cv <- glm(y ~ x1 + x2 +x3 +x4)
cv.error[4] <-cv.glm(model_four_data_set, model_four_with_data_set.cv, K=5)$delta[1]
print(cv.error)

#I spend 3 hours on those code, god its finally down.....
##################################################################################################################################

# The 5- fold corss-validation errors
#1.063516 1.085893 1.052645 1.143413

#low fold cross validation erros may relate to the problem of over fitting, 
#the AIC and BIC test are working on find the model that fit the data better with relative smllar variance

##################################################################################################################################




##################################################################################################################################
#Exercise 5 
rm(list = ls()) #clean the enviroment

##################################################################################################################################
#Exercise 5-a
#Create a matrix X (545 × 9) with the 7 explanatory variables described above plus experience and schooling squared. 
#Scale the matrix X such that all variables have the same variance. Create a vector y (545 × 1) with log wage.

#lode the data
DATA <- read.csv("data/males1987.csv", header = TRUE) 

#check the data
head(DATA, 5)
str(DATA)

#data is correct!






##################################################################################################################################
#now, I can finally rest in peace....

#God, this 




##################################################################################################################################
#now, I can finally rest in peace....





